# -*- coding: utf-8 -*-
"""QuantEdge Intelligence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gkmpljoOIvjbKUjTAM0G8OCGRZI-inXT
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from arch import arch_model
from datetime import datetime, timedelta
from scipy.stats import norm, skew, kurtosis
from scipy.optimize import fsolve
import statsmodels.api as sm

# --- LIGHT THEME UI & STYLING ---
st.set_page_config(page_title="QuantEdge Intelligence", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; color: #1e293b; }
    [data-testid="stMetricValue"] { color: #1e3a8a !important; font-weight: 800; }
    [data-testid="metric-container"] { 
        background-color: #ffffff; border: 1px solid #e2e8f0; 
        border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .valuation-card { 
        padding: 20px; border-radius: 12px; background-color: #ffffff; 
        border: 1px solid #e2e8f0; border-top: 4px solid #2563eb; 
        margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    }
    .status-undervalued { color: #16a34a; font-weight: bold; }
    .status-overvalued { color: #dc2626; font-weight: bold; }
    .linkedin-box {
        background-color: #0077b5; color: white !important;
        padding: 10px; border-radius: 8px; text-align: center;
        text-decoration: none; display: block; font-weight: bold; margin-top: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- SIDEBAR ---
with st.sidebar:
    st.title("üõ°Ô∏è QuantEdge 360¬∞")
    st.markdown("---")
    st.markdown("### **System Status**")
    st.info("Cache Active: Data refreshes every 60 mins to prevent Yahoo Rate Limits.")
    st.markdown("---")
    st.markdown("### **Developer**")
    st.markdown("**Sabarimayurnath U**")
    st.markdown(f'<a href="https://www.linkedin.com/in/sabarimayurnath-u/" target="_blank" class="linkedin-box">Connect on LinkedIn</a>', unsafe_allow_html=True)
    st.caption("¬© 2026 QuantPro Intelligence")

# --- TAB SETUP ---
tab_sel, tab1, tab2, tab3, tab4 = st.tabs(["üîç Selection", "üíé Real Valuation", "üèóÔ∏è Structure", "üîÆ Monte Carlo Strat", "üìâ Credit Risk"])

# --- TAB 0: SELECTION GATEWAY ---
with tab_sel:
    st.title("Asset Selection & Strategic Parameters")
    c1, c2 = st.columns(2)
    with c1:
        sel_mode = st.selectbox("Select Asset", ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "SBIN.NS", "TATAMOTORS.NS", "Others"])
        if sel_mode == "Others":
            sel_stock = st.text_input("Enter Yahoo Ticker", "ZOMATO.NS").upper()
        else: sel_stock = sel_mode
    with c2:
        lookback_yrs = st.slider("Lookback (Years)", 1, 10, 5)
        rf_rate_input = st.number_input("Risk Free Rate %", value=7.1)
        rf_rate = rf_rate_input / 100

# --- ROBUST DATA ENGINE (Cached 1 Hour) ---
@st.cache_data(ttl=3600, show_spinner="Fetching Data...")
def get_consolidated_data(ticker, yrs):
    """
    Fetches Price, Balance Sheet, and Info in one go. 
    Cached for 1 hour to avoid Rate Limits.
    """
    start_date = datetime.now() - timedelta(days=yrs*365 + 100) # Buffer for MA
    try:
        # 1. Fetch Price Data
        # We download Ticker + Benchmark (Nifty 50) together to align dates
        data = yf.download([ticker, "^NSEI"], start=start_date.strftime('%Y-%m-%d'), progress=False)['Close']
        
        # Handle MultiIndex if necessary
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(1)
            
        data = data.dropna().ffill()
        
        # 2. Fetch Fundamentals safely
        t_obj = yf.Ticker(ticker)
        
        # Try/Except block for fundamentals specifically
        try:
            info = t_obj.info
            bs = t_obj.balance_sheet
            mcap = info.get('marketCap', 0) / 1e7
            tot_d = info.get('totalDebt', 0) / 1e7
            
            # Smart Balance Sheet Parsing
            def get_val(items):
                for i in items:
                    matches = [k for k in bs.index if i.lower() in str(k).lower()]
                    if matches: return bs.loc[matches[0]].iloc[0] / 1e7
                return 0.0
                
            std = get_val(['Current Debt', 'Short Term Debt', 'ShortLongTermDebt'])
            ltd = get_val(['Long Term Debt'])
            if tot_d == 0: tot_d = std + ltd # Fallback
            
        except Exception as e:
            # Fallback if specific info fails
            mcap, tot_d, std, ltd = 1.0, 0.0, 0.0, 0.0
            print(f"Fundamental Warning: {e}")

        ltp = data[ticker].iloc[-1]
        
        return {
            "df": data, 
            "ltp": ltp, 
            "mcap": mcap, 
            "total_d": tot_d, 
            "st_d": std, 
            "lt_d": ltd,
            "success": True
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

# --- EXECUTION ---
res = get_consolidated_data(sel_stock, lookback_yrs)

if not res['success']:
    st.error(f"üõë Data Feed Error: {res.get('error')}")
    st.warning("Yahoo Finance Rate Limit likely hit. Please wait 1 hour or try a different ticker.")
    st.stop()

# Prepare Core Series
df = res['df']
stock_ret = df[sel_stock].pct_change().dropna()
mkt_ret = df['^NSEI'].pct_change().dropna()

# Align data lengths
common_idx = stock_ret.index.intersection(mkt_ret.index)
stock_ret = stock_ret.loc[common_idx]
mkt_ret = mkt_ret.loc[common_idx]

# --- TAB 1: REAL VALUATION (OLS) ---
with tab1:
    st.title(f"Valuation: {sel_stock}")
    st.caption("Using OLS Regression (Not Hardcoded Assumptions)")
    
    # 1. Advanced Metrics
    ann_ret = stock_ret.mean() * 252
    ann_vol = stock_ret.std() * np.sqrt(252)
    
    # 2. REAL OLS Regression (Jensen's Alpha)
    # Excess Returns
    y = stock_ret - (rf_rate/252)
    x = mkt_ret - (rf_rate/252)
    x = sm.add_constant(x)
    
    model = sm.OLS(y, x).fit()
    real_alpha = model.params['const'] * 252
    real_beta = model.params.iloc[1]
    r_squared = model.rsquared
    
    # CAPM Expected Return
    mkt_ann_ret = mkt_ret.mean() * 252
    exp_ret_capm = rf_rate + real_beta * (mkt_ann_ret - rf_rate)
    
    c1, c2, c3 = st.columns(3)
    c1.metric("Real Beta (Sensitivity)", f"{real_beta:.2f}")
    c2.metric("Jensen's Alpha", f"{real_alpha:.2%}", delta_color="normal")
    c3.metric("R-Squared (Fit)", f"{r_squared:.2f}")

    st.divider()
    
    v_col1, v_col2 = st.columns(2)
    
    # Valuation Display
    excess_return = ann_ret - exp_ret_capm
    status = "UNDERVALUED" if excess_return > 0 else "OVERVALUED"
    color = "status-undervalued" if excess_return > 0 else "status-overvalued"
    
    with v_col1:
        st.markdown(f"""
        <div class='valuation-card'>
            <h4>CAPM Intrinsic Valuation</h4>
            <p>Expected Return (Fair): <b>{exp_ret_capm:.2%}</b></p>
            <p>Actual CAGR: <b>{ann_ret:.2%}</b></p>
            <h3 class='{color}'>{status} by {abs(excess_return):.2%}</h3>
        </div>
        """, unsafe_allow_html=True)
        
    with v_col2:
        st.write("**Interpretation:**")
        st.write(f"- The stock generates **{real_alpha:.2%}** excess return (Alpha) unrelated to market movements.")
        st.write(f"- A Beta of **{real_beta:.2f}** means it is {'more' if real_beta > 1 else 'less'} volatile than the Nifty 50.")

# --- TAB 2: STRUCTURE ---
with tab2:
    st.title("Technical Structure")
    df['MA50'] = df[sel_stock].rolling(50).mean()
    df['MA200'] = df[sel_stock].rolling(200).mean()
    
    curr = res['ltp']
    ma200 = df['MA200'].iloc[-1]
    
    st.metric("Price vs 200-DMA", f"{((curr/ma200)-1):.2%}", 
             "Bullish" if curr > ma200 else "Bearish")
             
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df.index, y=df[sel_stock], name="Price", line=dict(color='black', width=1)))
    fig.add_trace(go.Scatter(x=df.index, y=df['MA50'], name="50 DMA", line=dict(color='blue', width=1)))
    fig.add_trace(go.Scatter(x=df.index, y=df['MA200'], name="200 DMA", line=dict(color='red', width=2)))
    st.plotly_chart(fig, use_container_width=True)

# --- TAB 3: MONTE CARLO SIMULATION ---
with tab3:
    st.title("Probabilistic Future (Monte Carlo)")
    st.caption("Simulating 1,000 future paths using GARCH volatility clustering.")
    
    if st.button("Run Simulation (Heavy Compute)"):
        with st.spinner("Crunching 1,000 scenarios..."):
            # 1. GARCH Volatility Forecast
            am = arch_model(stock_ret * 100, vol='Garch', p=1, q=1, dist='Normal')
            garch_fit = am.fit(disp="off")
            curr_vol = garch_fit.conditional_volatility.iloc[-1] / 100
            
            # 2. Vectorized Monte Carlo
            days = 252
            sims = 1000
            dt = 1/252
            
            # Drift based on CAPM expectation (Conservative)
            drift = (exp_ret_capm - 0.5 * curr_vol**2) * dt
            
            # Random Shocks matrix
            Z = np.random.normal(0, 1, (days, sims))
            
            # Price Paths Matrix
            price_paths = np.zeros((days, sims))
            price_paths[0] = res['ltp']
            
            for t in range(1, days):
                price_paths[t] = price_paths[t-1] * np.exp(drift + curr_vol * np.sqrt(dt) * Z[t])
            
            # 3. Analysis
            final_prices = price_paths[-1]
            prob_profit = np.mean(final_prices > res['ltp'])
            exp_price = np.mean(final_prices)
            
            m1, m2, m3 = st.columns(3)
            m1.metric("Probability of Profit", f"{prob_profit:.1%}")
            m2.metric("Exp. Price (1 Yr)", f"‚Çπ{exp_price:,.2f}")
            m3.metric("VaR (95% Worst Case)", f"‚Çπ{np.percentile(final_prices, 5):,.2f}")
            
            # 4. Cone Chart
            fig_mc = go.Figure()
            # Plot only 50 paths for visibility
            for i in range(50):
                fig_mc.add_trace(go.Scatter(y=price_paths[:, i], mode='lines', line=dict(width=0.5, color='rgba(100,100,100,0.1)'), showlegend=False))
            
            # Percentiles
            p95 = np.percentile(price_paths, 95, axis=1)
            p05 = np.percentile(price_paths, 5, axis=1)
            p50 = np.percentile(price_paths, 50, axis=1)
            
            fig_mc.add_trace(go.Scatter(y=p95, mode='lines', name='95th % (Optimistic)', line=dict(color='green')))
            fig_mc.add_trace(go.Scatter(y=p50, mode='lines', name='Median', line=dict(color='blue', dash='dash')))
            fig_mc.add_trace(go.Scatter(y=p05, mode='lines', name='5th % (Crash)', line=dict(color='red')))
            
            st.plotly_chart(fig_mc, use_container_width=True)

# --- TAB 4: CREDIT RISK ---
with tab4:
    st.title("Credit Risk (Merton/KMV)")
    
    if res['total_d'] <= 0 or res['mcap'] <= 0:
        st.warning("‚ö†Ô∏è Insufficient Debt or Market Cap data to model default risk.")
    else:
        # User Inputs
        c1, c2 = st.columns(2)
        with c1:
            # Default Barrier: Short Term + 50% Long Term (KMV standard)
            def_barrier = st.number_input("Default Barrier (Cr)", value=float(res['st_d'] + 0.5*res['lt_d']))
        with c2:
            time_h = st.number_input("Time Horizon (Yrs)", 1.0)
            
        st.table(pd.DataFrame({
            "Metric": ["Market Cap", "Total Debt", "Asset Volatility (Est)"],
            "Value (Cr)": [f"{res['mcap']:,.0f}", f"{res['total_d']:,.0f}", f"{ann_vol:.2%}"]
        }))
        
        # Solver
        def merton_solve(E, vol_E, D, r, T):
            def equations(vars):
                V, vol_V = vars
                d1 = (np.log(V/D) + (r + 0.5*vol_V**2)*T) / (vol_V*np.sqrt(T))
                d2 = d1 - vol_V*np.sqrt(T)
                eq1 = V * norm.cdf(d1) - D*np.exp(-r*T) * norm.cdf(d2) - E
                eq2 = (V/E) * norm.cdf(d1) * vol_V - vol_E
                return [eq1, eq2]
            
            # Initial guess: V = E+D, vol_V = vol_E * 0.5
            return fsolve(equations, [E+D, vol_E*0.5])

        try:
            V_sol, vol_V_sol = merton_solve(res['mcap'], ann_vol, def_barrier, rf_rate, time_h)
            
            # Distance to Default
            dd = (np.log(V_sol/def_barrier) + (rf_rate - 0.5*vol_V_sol**2)*time_h) / (vol_V_sol*np.sqrt(time_h))
            pd_val = norm.cdf(-dd)
            
            kmv_c1, kmv_c2 = st.columns(2)
            kmv_c1.metric("Distance to Default", f"{dd:.2f} œÉ")
            kmv_c2.metric("Implied Prob. Default", f"{pd_val:.5%}", delta_color="inverse")
            
            if pd_val > 0.05:
                st.error("HIGH RISK: Default probability > 5%")
            else:
                st.success("STABLE: Default probability < 5%")
                
        except Exception as e:
            st.error(f"Solver failed to converge. Data may be extreme. {e}")


