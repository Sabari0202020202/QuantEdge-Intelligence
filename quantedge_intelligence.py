# -*- coding: utf-8 -*-
"""QuantEdge Intelligence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gkmpljoOIvjbKUjTAM0G8OCGRZI-inXT
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from arch import arch_model
from datetime import datetime, timedelta
from scipy.stats import norm, skew, kurtosis
from scipy.optimize import fsolve

# --- LIGHT THEME UI & STYLING ---
st.set_page_config(page_title="QuantPro Advisor | Sabarimayurnath U", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; color: #1e293b; }
    [data-testid="stMetricValue"] { color: #1e3a8a !important; font-weight: 800; }
    [data-testid="metric-container"] { 
        background-color: #ffffff; border: 1px solid #e2e8f0; 
        border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .valuation-card { 
        padding: 20px; border-radius: 12px; background-color: #ffffff; 
        border: 1px solid #e2e8f0; border-top: 4px solid #2563eb; 
        margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    }
    .status-undervalued { color: #16a34a; font-weight: bold; }
    .status-overvalued { color: #dc2626; font-weight: bold; }
    .linkedin-box {
        background-color: #0077b5; color: white !important;
        padding: 10px; border-radius: 8px; text-align: center;
        text-decoration: none; display: block; font-weight: bold; margin-top: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- SIDEBAR: PERSONAL BRANDING ---
with st.sidebar:
    st.title("üõ°Ô∏è QuantPro Intelligence")
    st.markdown("---")
    st.markdown("### **Key Capabilities**")
    st.markdown("""
    * **Risk-Adjusted Metrics:** *Sortino, Calmar, Ulcer Index*
    * **Structural DNA:** *Institutional 200-MA filters*
    * **Volatility Forecasting:** *GARCH (1,1) Risk Regimes*
    * **Credit Risk:** *Merton & KMV Probability of Default*
    """)
    st.markdown("---")
    st.markdown("### **Developer Profile**")
    st.markdown("**Name:** *Sabarimayurnath U*")
    st.markdown("**Email:** `u.sabarimayurnath@gmail.com`")
    st.markdown(f'<a href="https://www.linkedin.com/in/sabarimayurnath-u/" target="_blank" class="linkedin-box">Connect on LinkedIn</a>', unsafe_allow_html=True)
    st.markdown("---")
    st.caption("¬© 2026 QuantPro Intelligence")

# --- TAB SETUP ---
tab_sel, tab1, tab2, tab3, tab4 = st.tabs(["üîç Selection", "üíé Valuation", "üèóÔ∏è Structure", "üîÆ Strategy", "üìâ Credit Risk"])

# --- TAB 0: SELECTION GATEWAY ---
with tab_sel:
    st.title("Asset Selection & Strategic Parameters")
    st.subheader("1. Asset Selection")
    sel_mode = st.selectbox("Select Asset", ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "SBIN.NS", "TATAMOTORS.NS", "Others"])
    if sel_mode == "Others":
        sel_stock = st.text_input("Enter Yahoo Ticker (e.g. ZOMATO.NS)", "ZOMATO.NS").upper()
    else: sel_stock = sel_mode
    st.caption("*Justification: Defines the universe of data for all valuation and risk models.*")
    
    st.subheader("2. Historical Timeframe")
    lookback = st.slider("Years of Data", 1, 15, 5)
    st.caption("*Justification: Longer timeframes provide equilibrium 'Alpha', while shorter ones capture recent regime shifts.*")

    st.subheader("3. Risk-Free Rate")
    rf_rate = st.number_input("Risk Free Rate %", value=7.1) / 100
    st.caption("*Justification: The benchmark hurdle rate for calculating CAPM and Sharpe ratio.*")

# --- DATA ENGINE ---
@st.cache_data
def get_processed_data(ticker, yrs):
    start = datetime.now() - timedelta(days=yrs*365 + 365) 
    try:
        df = yf.download([ticker, "^NSEI", "^NSEBANK"], start=start.strftime('%Y-%m-%d'))['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(1)
        df = df.dropna(subset=[ticker]).ffill()
        t_obj = yf.Ticker(ticker)
        ltp = t_obj.history(period="1d")['Close'].iloc[-1]
        t_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return df, ltp, t_stamp
    except: return None, None, None

data, ltp, ltp_time = get_processed_data(sel_stock, lookback)

if data is not None:
    # --- TAB 1: ADVANCED VALUATION & RATIOS ---
    with tab1:
        st.title(f"Valuation: {sel_stock}")
        st.write(f"**LTP:** ‚Çπ{ltp:,.2f} | **As of:** {ltp_time}")
        
        returns = data[sel_stock].pct_change().dropna()
        mkt_rets = data["^NSEI"].pct_change().dropna()
        
        # 1. Performance Ratios
        cagr = (data[sel_stock].iloc[-1] / data[sel_stock].iloc[0])**(1/lookback) - 1
        ann_vol = returns.std() * np.sqrt(252)
        sharpe = (ann_ret := returns.mean()*252 - rf_rate) / ann_vol
        
        downside_rets = returns[returns < 0]
        downside_dev = downside_rets.std() * np.sqrt(252)
        sortino = (returns.mean()*252 - rf_rate) / downside_dev if downside_dev != 0 else 0
        
        dd = (data[sel_stock] - data[sel_stock].cummax()) / data[sel_stock].cummax()
        max_dd = dd.min()
        calmar = (returns.mean()*252) / abs(max_dd) if max_dd != 0 else 0
        
        # 2. Risk Metrics
        var_95 = np.percentile(returns, 5)
        cvar_95 = returns[returns <= var_95].mean()
        ulcer_index = np.sqrt(np.mean(dd**2))
        
        # 3. Market Metrics
        cov = returns.cov(mkt_rets) * 252
        mkt_var = mkt_rets.var() * 252
        beta = cov / mkt_var
        alpha = (returns.mean() * 252) - (rf_rate + beta * (mkt_rets.mean()*252 - rf_rate))
        
        # 4. Trading Metrics
        win_rate = len(returns[returns > 0]) / len(returns)
        profit_factor = abs(returns[returns > 0].sum() / returns[returns < 0].sum())
        gain_to_pain = returns.sum() / abs(returns[returns < 0].sum())

        # DISPLAY
        st.subheader("Core Statistics & Risk-Adjusted Ratios")
        m_row1 = st.columns(4)
        m_row1[0].metric("CAGR", f"{cagr:.2%}")
        m_row1[1].metric("Sharpe Ratio", f"{sharpe:.2f}")
        m_row1[2].metric("Sortino Ratio", f"{sortino:.2f}")
        m_row1[3].metric("Calmar Ratio", f"{calmar:.2f}")

        m_row2 = st.columns(4)
        m_row2[0].metric("Max Drawdown", f"{max_dd:.2%}")
        m_row2[1].metric("Avg Drawdown", f"{dd.mean():.2%}")
        m_row2[2].metric("Ulcer Index", f"{ulcer_index:.2f}")
        m_row2[3].metric("Ann. Volatility", f"{ann_vol:.2%}")

        m_row3 = st.columns(4)
        m_row3[0].metric("VaR (95%)", f"{var_95:.2%}")
        m_row3[1].metric("CVaR (95%)", f"{cvar_95:.2%}")
        m_row3[2].metric("Skewness", f"{skew(returns):.2f}")
        m_row3[3].metric("Kurtosis", f"{kurtosis(returns):.2f}")

        m_row4 = st.columns(4)
        m_row4[0].metric("Profit Factor", f"{profit_factor:.2f}")
        m_row4[1].metric("Win Rate", f"{win_rate:.2%}")
        m_row4[2].metric("Beta", f"{beta:.2f}")
        m_row4[3].metric("Alpha (Ann.)", f"{alpha:.2%}")

    # --- TAB 2: STRUCTURE ---
    with tab2:
        st.title("Structural DNA & Interpretation")
        data['MA50'], data['MA200'] = data[sel_stock].rolling(50).mean(), data[sel_stock].rolling(200).mean()
        
        c_t1, c_t2, c_t3 = st.columns(3)
        with c_t1: 
            st.metric("Trend vs 200-MA", "‚úÖ BULLISH" if ltp > data['MA200'].iloc[-1] else "‚ùå BEARISH")
            st.write("**Interp:** Institutional line. Above = Accumulation; Below = Distribution.")
        with c_t2:
            st.metric("50/200 MA Cross", "üî• GOLDEN" if data['MA50'].iloc[-1] > data['MA200'].iloc[-1] else "‚ùÑÔ∏è DEATH")
            st.write("**Interp:** Golden signals long momentum; Death signals structural decay.")
        with c_t3:
            st.metric("Dist. 52W High", f"{((ltp / data[sel_stock].max())-1):.2%}")
            st.write("**Interp:** Relative strength. Low distance implies high market demand.")

        st.subheader("Relative Strength & Drawdown Profile")
        rs = (data[sel_stock].iloc[-1]/data[sel_stock].iloc[-22]) - (data['^NSEI'].iloc[-1]/data['^NSEI'].iloc[-22])
        st.metric("Relative Strength (1M)", f"{rs:+.2%}", delta="vs Nifty 50")
        
        res, supp = data[sel_stock].tail(22).max(), data[sel_stock].tail(22).min()
        fig_sr = go.Figure()
        fig_sr.add_trace(go.Scatter(x=data.tail(252).index, y=data[sel_stock].tail(252), name="Price"))
        fig_sr.add_hline(y=res, line_dash="dash", line_color="green", annotation_text="Resis")
        fig_sr.add_hline(y=supp, line_dash="dash", line_color="red", annotation_text="Supp")
        st.plotly_chart(fig_sr, use_container_width=True)

    # --- TAB 3: STRATEGY ---
    with tab3:
        st.title("Volatility Engine & Strategy Forecast")
        ret_g = 100 * returns
        am = arch_model(ret_g, vol='Garch', p=1, q=1, dist='t')
        res_g = am.fit(disp="off")
        
        with st.expander("üîç GARCH (1,1) Statistical Summary"):
            st.text(res_g.summary())
        
        st.metric("Current Shock Volatility", f"{res_g.conditional_volatility.iloc[-1]:.2f}")
        fig_v = go.Figure()
        fig_v.add_trace(go.Scatter(x=res_g.conditional_volatility.index, y=res_g.conditional_volatility, name="Shock Vol", line=dict(color='orange')))
        st.plotly_chart(fig_v, use_container_width=True)

        st.divider()
        # Strategy selection
        s_choice = st.selectbox("Select Strategy", ["RSI", "SMA Crossover", "Triple Golden Cross"])
        
        # Forecast Path
        f_vol = np.sqrt(res_g.forecast(horizon=252).variance.values[-1, :]) / 100
        p_f = [ltp]; np.random.seed(42)
        for i in range(252): p_f.append(p_f[-1] * np.exp(returns.mean() + f_vol[i] * np.random.standard_normal()))
        df_f = pd.DataFrame({'Close': p_f[1:]}, index=[data.index[-1] + timedelta(days=i) for i in range(1, 253)])
        
        if s_choice == "RSI":
            per = st.slider("RSI Period", 7, 30, 14)
            delta = df_f['Close'].diff(); g = (delta.where(delta > 0, 0)).rolling(per).mean(); l = (-delta.where(delta < 0, 0)).rolling(per).mean()
            df_f['RSI'] = 100 - (100 / (1 + (g/l))); df_f['Signal'] = np.where(df_f['RSI'] < 30, 1, 0)
        elif s_choice == "SMA Crossover":
            f_p, s_p = st.columns(2); fast = f_p.number_input("Fast", 20); slow = s_p.number_input("Slow", 50)
            df_f['Signal'] = np.where(df_f['Close'].rolling(fast).mean() > df_f['Close'].rolling(slow).mean(), 1, 0)
        elif s_choice == "Triple Golden Cross":
            ts, tm, tl = st.columns(3); s_ = ts.number_input("Short", 10); m_ = tm.number_input("Mid", 50); l_ = tl.number_input("Long", 200)
            df_f['MS'], df_f['MM'], df_f['ML'] = df_f['Close'].rolling(s_).mean(), df_f['Close'].rolling(m_).mean(), df_f['Close'].rolling(l_).mean()
            df_f['Signal'] = np.where((df_f['MS'] > df_f['MM']) & (df_f['MS'] < df_f['ML']), 1, 0)

        # Metrics Table
        s_ret = df_f['Signal'].shift(1) * df_f['Close'].pct_change()
        st.table(pd.DataFrame({
            "Metric": ["Ann. Return", "Ann. Risk", "Sharpe", "Trades"],
            "Value": [f"{s_ret.mean()*252:.2%}", f"{s_ret.std()*np.sqrt(252):.2%}", f"{(s_ret.mean()*252)/(s_ret.std()*np.sqrt(252)):.2f}", int(df_f['Signal'].diff().abs().sum())]
        }))
        
        fig_f = go.Figure()
        fig_f.add_trace(go.Scatter(x=df_f.index, y=df_f['Close'], name="Forecast"))
        buys = df_f[df_f['Signal'].diff() == 1]; sells = df_f[df_f['Signal'].diff() == -1]
        fig_f.add_trace(go.Scatter(x=buys.index, y=buys['Close'], mode='markers', marker=dict(symbol='triangle-up', size=12, color='green')))
        fig_f.add_trace(go.Scatter(x=sells.index, y=sells['Close'], mode='markers', marker=dict(symbol='triangle-down', size=12, color='red')))
        st.plotly_chart(fig_f, use_container_width=True)

    # --- TAB 4: CREDIT RISK ---
    with tab4:
        st.title("Credit Risk: Merton/KMV Probability of Default")
        @st.cache_data(ttl=3600)
        def get_debt(t):
            t_o = yf.Ticker(t); bs = t_o.balance_sheet; info = t_o.info
            def v(keys):
                for k in keys:
                    m = [i for i in bs.index if k.lower() in str(i).lower()]
                    if m: return bs.loc[m[0]].iloc[0] / 1e7
                return 0.0
            std = v(['Current Debt', 'Short Term Borrowings']); ltd = v(['Long Term Debt', 'Long Term Borrowings'])
            return std, ltd, info.get('totalDebt', 0)/1e7, info.get('marketCap', 1)/1e7

        std, ltd, total_d, mcap = get_debt(sel_stock)
        st.table(pd.DataFrame({"Component": ["ST Debt", "LT Debt", "Total Debt", "Market Cap"], "Value (Cr ‚Çπ)": [f"{std:,.2f}", f"{ltd:,.2f}", f"{total_d:,.2f}", f"{mcap:,.2f}"]}))
        
        m_type = st.radio("Framework", ["Merton", "KMV"])
        bar = (std + 0.5 * ltd) if m_type == "KMV" else total_d
        bar = st.number_input("Default Barrier", value=float(bar) if bar > 0 else 5000.0)
        
        def solve_m(E, se, L, r, T):
            def eq(p):
                V, sv = p; d1 = (np.log(V/L) + (r + 0.5 * sv**2) * T) / (sv * np.sqrt(T)); d2 = d1 - sv * np.sqrt(T)
                return [V * norm.cdf(d1) - L * np.exp(-r * T) * norm.cdf(d2) - E, (norm.cdf(d1) * V / E) * sv - se]
            return fsolve(eq, [E + L, se * (E / (E + L))])

        try:
            va, sa = solve_m(mcap, ann_vol, bar, rf_rate, 1.0)
            dd = (np.log(va/bar) + (rf_rate - 0.5 * sa**2)) / sa; pd_v = norm.cdf(-dd)
            c1, c2 = st.columns(2)
            c1.metric("Distance to Default (DD)", f"{dd:.2f} œÉ")
            c2.metric("Prob. of Default (PD)", f"{pd_v:.4%}")
            st.divider()
            st.write(f"**Interpretation:** Firm is **{dd:.2f} standard deviations** from insolvency. A DD below 2.0œÉ signals critical structural weakness.")
        except: st.error("Solver Failure.")

else: st.error("Data Load Failed.")

