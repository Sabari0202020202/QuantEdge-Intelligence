# -*- coding: utf-8 -*-
"""QuantEdge Intelligence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gkmpljoOIvjbKUjTAM0G8OCGRZI-inXT
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from arch import arch_model
from datetime import datetime, timedelta
from scipy.stats import norm, skew, kurtosis
from scipy.optimize import fsolve

# --- LIGHT THEME UI & STYLING ---
st.set_page_config(page_title="QuantPro Advisor | Sabarimayurnath U", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; color: #1e293b; }
    [data-testid="stMetricValue"] { color: #1e3a8a !important; font-weight: 800; }
    [data-testid="metric-container"] { 
        background-color: #ffffff; border: 1px solid #e2e8f0; 
        border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .valuation-card { 
        padding: 20px; border-radius: 12px; background-color: #ffffff; 
        border: 1px solid #e2e8f0; border-top: 4px solid #2563eb; 
        margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    }
    .status-undervalued { color: #16a34a; font-weight: bold; }
    .status-overvalued { color: #dc2626; font-weight: bold; }
    .linkedin-box {
        background-color: #0077b5; color: white !important;
        padding: 10px; border-radius: 8px; text-align: center;
        text-decoration: none; display: block; font-weight: bold; margin-top: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- SIDEBAR: PERSONAL BRANDING & CAPABILITIES ---
with st.sidebar:
    st.title("üõ°Ô∏è QuantPro Intelligence")
    st.markdown("---")
    st.markdown("### **Key Capabilities**")
    st.markdown("""
    1. **Advanced Risk Suite:** Sharpe, Sortino, Calmar, Ulcer Index, and CVaR.
    2. **Multi-Factor Valuation:** Alpha analysis via CAPM, 4-Factor, and APT.
    3. **Structural DNA:** Institutional 200-MA filters and Support/Resistance memory.
    4. **Volatility Forecasting:** GARCH (1,1) modeling for risk regimes.
    5. **Strategy Backtester:** Triple-MA Cluster logic and RSI execution.
    6. **Credit Risk Analysis:** Merton/KMV models for Probability of Default.
    """)
    st.markdown("---")
    st.markdown("### **Developer Profile**")
    st.markdown("**Name:** *Sabarimayurnath U*")
    st.markdown("**Email:** `u.sabarimayurnath@gmail.com`")
    st.markdown(f'<a href="https://www.linkedin.com/in/sabarimayurnath-u/" target="_blank" class="linkedin-box">Connect on LinkedIn</a>', unsafe_allow_html=True)
    st.markdown("---")
    st.caption("¬© 2026 QuantPro Intelligence")

# --- TAB SETUP ---
tab_sel, tab1, tab2, tab3, tab4 = st.tabs(["üîç Selection", "üíé Analysis & Valuation", "üèóÔ∏è Structure", "üîÆ Strategy", "üìâ Credit Risk"])

# --- TAB 0: SELECTION GATEWAY ---
with tab_sel:
    st.title("Asset Selection & Strategic Parameters")
    st.subheader("1. Asset Selection")
    sel_mode = st.selectbox("Select Asset", ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "SBIN.NS", "TATAMOTORS.NS", "Others"])
    if sel_mode == "Others":
        sel_stock = st.text_input("Enter Yahoo Ticker", "ZOMATO.NS").upper()
    else: sel_stock = sel_mode
    st.caption("*Justification: Defines the universe of data for all valuation and risk models.*")
    
    st.subheader("2. Historical Timeframe")
    lookback_yrs = st.slider("Years of Data", 1, 15, 5)
    st.caption("*Justification: Longer timeframes provide equilibrium 'Alpha', while shorter ones capture recent regime shifts.*")

    st.subheader("3. Risk-Free Rate")
    rf_rate_input = st.number_input("Risk Free Rate %", value=7.1)
    rf_rate = rf_rate_input / 100
    st.caption("*Justification: The benchmark hurdle rate for calculating CAPM and Sharpe ratio.*")

# --- DATA ENGINE ---
@st.cache_data
def get_processed_data(ticker, yrs):
    start = datetime.now() - timedelta(days=yrs*365 + 365) 
    try:
        df = yf.download([ticker, "^NSEI", "^NSEBANK"], start=start.strftime('%Y-%m-%d'))['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(1)
        df = df.dropna(subset=[ticker]).ffill()
        t_obj = yf.Ticker(ticker)
        ltp = t_obj.history(period="1d")['Close'].iloc[-1]
        t_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return df, ltp, t_stamp
    except: return None, None, None

data, ltp, ltp_time = get_processed_data(sel_stock, lookback_yrs)

if data is not None:
    returns = data[sel_stock].pct_change().dropna()
    mkt_rets = data["^NSEI"].pct_change().dropna()
    ann_ret_raw = returns.mean() * 252
    ann_vol = returns.std() * np.sqrt(252)

    # --- TAB 1: ANALYSIS & VALUATION ---
    with tab1:
        st.title(f"Analysis & Valuation: {sel_stock}")
        st.write(f"**LTP:** ‚Çπ{ltp:,.2f} | **As of:** {ltp_time}")
        
        # 1. High-Density Ratios
        cagr = (data[sel_stock].iloc[-1] / data[sel_stock].iloc[0])**(1/lookback_yrs) - 1
        sharpe = (ann_ret_raw - rf_rate) / ann_vol if ann_vol != 0 else 0
        downside_dev = returns[returns < 0].std() * np.sqrt(252)
        sortino = (ann_ret_raw - rf_rate) / downside_dev if downside_dev != 0 else 0
        dd = (data[sel_stock] - data[sel_stock].cummax()) / data[sel_stock].cummax()
        max_dd = dd.min()
        calmar = ann_ret_raw / abs(max_dd) if max_dd != 0 else 0
        var_95 = np.percentile(returns, 5)
        cvar_95 = returns[returns <= var_95].mean()
        ulcer_index = np.sqrt(np.mean(dd**2))
        beta = (returns.cov(mkt_rets) * 252) / (mkt_rets.var() * 252)
        win_rate = len(returns[returns > 0]) / len(returns)
        profit_factor = abs(returns[returns > 0].sum() / returns[returns < 0].sum()) if returns[returns < 0].sum() != 0 else 0
        alpha_capm = ann_ret_raw - (rf_rate + beta * (mkt_rets.mean()*252 - rf_rate))

        # 2. Multi-Factor Valuation Engine
        st.subheader("Multi-Factor Valuation Alphas")
        capm_exp = rf_rate + beta * (mkt_rets.mean()*252 - rf_rate)
        ff_exp = rf_rate + (beta * 0.08) + (returns.rolling(252).corr(data['^NSEBANK'].pct_change()).iloc[-1] * 0.02)
        apt_exp = capm_exp + 0.015

        v_cols = st.columns(3)
        def draw_v_card(col, name, exp, actual, help_t):
            al = actual - exp
            vc = "status-undervalued" if al > 0 else "status-overvalued"
            col.markdown(f"""<div class='valuation-card' title='{help_t}'><small>{name}</small><h3>Exp: {exp:.2%}</h3>
                        <p class='{vc}'>Alpha: {al:+.2%} ({"Undervalued" if al > 0 else "Overvalued"})</p></div>""", unsafe_allow_html=True)
        draw_v_card(v_cols[0], "CAPM Model", capm_exp, cagr, "Market-risk adjusted baseline.")
        draw_v_card(v_cols[1], "4-Factor Model", ff_exp, cagr, "Market + Size + Momentum proxies.")
        draw_v_card(v_cols[2], "APT Model", apt_exp, cagr, "Macro-factor sector proxy.")

        st.divider()
        st.subheader("19-Point Advanced Risk & Performance Suite")
        r_cols = st.columns(4)
        r_cols[0].metric("Sharpe Ratio", f"{sharpe:.2f}", help="Return per unit of total risk.")
        r_cols[1].metric("Sortino Ratio", f"{sortino:.2f}", help="Return per unit of downside risk.")
        r_cols[2].metric("Calmar Ratio", f"{calmar:.2f}", help="Return vs Max Drawdown.")
        r_cols[3].metric("CAGR", f"{cagr:.2%}", help="Compound Annual Growth Rate.")

        r_cols2 = st.columns(4)
        r_cols2[0].metric("Max Drawdown", f"{max_dd:.2%}", help="Worst peak-to-trough decline.")
        r_cols2[1].metric("Avg Drawdown", f"{dd.mean():.2%}", help="Average decline from historical peaks.")
        r_cols2[2].metric("Ulcer Index", f"{ulcer_index:.2f}", help="Drawdown stress measurement.")
        r_cols2[3].metric("Ann. Volatility", f"{ann_vol:.2%}", help="Annualized Standard Deviation.")

        r_cols3 = st.columns(4)
        r_cols3[0].metric("Downside Deviation", f"{downside_dev:.2%}", help="Risk of negative returns.")
        r_cols3[1].metric("VaR (95%)", f"{var_95:.2%}", help="Daily Value at Risk.")
        r_cols3[2].metric("CVaR (95%)", f"{cvar_95:.2%}", help="Expected Shortfall.")
        r_cols3[3].metric("Skewness", f"{skew(returns):.2f}", help="Asymmetry of distribution.")

        r_cols4 = st.columns(4)
        r_cols4[0].metric("Kurtosis", f"{kurtosis(returns):.2f}", help="Fat-tail risk measurement.")
        r_cols4[1].metric("Win Rate", f"{win_rate:.2%}", help="Percentage of positive return days.")
        r_cols4[2].metric("Profit Factor", f"{profit_factor:.2f}", help="Gross Profit / Gross Loss.")
        r_cols4[3].metric("Gain-to-Pain", f"{returns.sum()/abs(returns[returns<0].sum()):.2f}", help="Total return per unit of loss.")

        r_cols5 = st.columns(3)
        r_cols5[0].metric("Beta", f"{beta:.2f}", help="Sensitivity to Nifty 50.")
        r_cols5[1].metric("Alpha (Ann.)", f"{alpha_val:.2%}", help="Excess return above CAPM benchmark.")
        r_cols5[2].metric("Information Ratio", f"{alpha_val/ann_vol:.2f}", help="Active return per unit of active risk.")

    # --- TAB 2: STRUCTURE ---
    with tab2:
        st.title("Structural DNA & Trend Analysis")
        data['MA50'], data['MA200'] = data[sel_stock].rolling(50).mean(), data[sel_stock].rolling(200).mean()
        
        c_tr1, c_tr2, c_tr3 = st.columns(3)
        with c_tr1:
            st.metric("Trend vs 200-MA", "‚úÖ BULLISH" if ltp > data['MA200'].iloc[-1] else "‚ùå BEARISH")
            st.write("**Interp:** Above 200-MA signals long-term institutional accumulation.")
        with c_tr2:
            st.metric("50/200 MA Cross", "üî• GOLDEN" if data['MA50'].iloc[-1] > data['MA200'].iloc[-1] else "‚ùÑÔ∏è DEATH")
            st.write("**Interp:** Golden signals momentum alignment; Death signals exhaustion.")
        with c_tr3:
            st.metric("Dist. 52W High", f"{((ltp / data[sel_stock].max())-1):.2%}")
            st.write("**Interp:** Proximity to high indicates buying demand.")

        res, supp = data[sel_stock].tail(22).max(), data[sel_stock].tail(22).min()
        st.subheader("Price Memory Chart (22-Day Support/Resistance)")
        fig_sr = go.Figure()
        fig_sr.add_trace(go.Scatter(x=data.tail(252).index, y=data[sel_stock].tail(252), name="Price"))
        fig_sr.add_hline(y=res, line_dash="dash", line_color="green", annotation_text="Resis")
        fig_sr.add_hline(y=supp, line_dash="dash", line_color="red", annotation_text="Supp")
        st.plotly_chart(fig_sr, use_container_width=True)

    # --- TAB 3: STRATEGY ---
    with tab3:
        st.title("GARCH (1,1) Volatility & Strategy Forecast")
        ret_g = 100 * returns
        am = arch_model(ret_g, vol='Garch', p=1, q=1, dist='t')
        res_g = am.fit(disp="off")
        
        st.subheader("Volatility Status")
        m_vol1, m_vol2 = st.columns(2)
        m_vol1.metric("Current Shock Volatility", f"{res_g.conditional_volatility.iloc[-1]:.2f}")
        m_vol2.metric("Persistence (Beta)", f"{res_g.params['beta[1]']:.3f}")

        with st.expander("üîç View GARCH (1,1) Statistical Model Summary"):
            st.text(res_g.summary())

        fig_v = go.Figure()
        fig_v.add_trace(go.Scatter(x=res_g.conditional_volatility.index, y=res_g.conditional_volatility, name="Predicted Volatility", line=dict(color='orange')))
        st.plotly_chart(fig_v, use_container_width=True)
        

        st.divider()
        st.subheader("Strategy Playbook Selection")
        strat_choice = st.selectbox("Methodology", ["Triple Golden Cross", "RSI", "SMA Crossover"])
        
        # 1-Year GARCH Forecast
        f_vol = np.sqrt(res_g.forecast(horizon=252).variance.values[-1, :]) / 100
        p_f = [ltp]; np.random.seed(42)
        for i in range(252): p_f.append(p_f[-1] * np.exp(returns.mean() + f_vol[i] * np.random.standard_normal()))
        df_f = pd.DataFrame({'Close': p_f[1:]}, index=[data.index[-1] + timedelta(days=i) for i in range(1, 253)])
        
        if strat_choice == "Triple Golden Cross":
            t_col1, t_col2, t_col3 = st.columns(3)
            s_p = t_col1.number_input("Short MA", 10); m_p = t_col2.number_input("Mid MA", 50); l_p = t_col3.number_input("Long MA", 200)
            df_f['S'], df_f['M'], df_f['L'] = df_f['Close'].rolling(s_p).mean(), df_f['Close'].rolling(m_p).mean(), df_f['Close'].rolling(l_p).mean()
            # Logic: Buy if Short > Mid while both are below Long (early recovery)
            df_f['Signal'] = np.where((df_f['S'] > df_f['M']) & (df_f['S'] < df_f['L']), 1, 0)
        elif strat_choice == "RSI":
            r_p = st.slider("RSI Period", 7, 30, 14)
            delta = df_f['Close'].diff(); g = delta.where(delta > 0, 0).rolling(r_p).mean(); l = -delta.where(delta < 0, 0).rolling(r_p).mean()
            df_f['RSI'] = 100 - (100 / (1 + (g/l))); df_f['Signal'] = np.where(df_f['RSI'] < 30, 1, 0)
        else:
            fast = st.number_input("Fast SMA", 20); slow = st.number_input("Slow SMA", 50)
            df_f['Signal'] = np.where(df_f['Close'].rolling(fast).mean() > df_f['Close'].rolling(slow).mean(), 1, 0)

        # Result Summary Table
        s_ret_fore = df_f['Signal'].shift(1) * df_f['Close'].pct_change()
        st.subheader("Forecasted Performance Table (1-Year)")
        st.table(pd.DataFrame({
            "Metric": ["Annualized Return", "Annualized Risk", "Sharpe Value", "No. of Trades"],
            "Forecast": [f"{s_ret_fore.mean()*252:.2%}", f"{s_ret_fore.std()*np.sqrt(252):.2%}", f"{(s_ret_fore.mean()*252)/(s_ret_fore.std()*np.sqrt(252)):.2f}", int(df_f['Signal'].diff().abs().sum())]
        }))
        
        fig_f = go.Figure()
        fig_f.add_trace(go.Scatter(x=df_f.index, y=df_f['Close'], name="Forecasted Price"))
        buys = df_f[df_f['Signal'].diff() == 1]; sells = df_f[df_f['Signal'].diff() == -1]
        fig_f.add_trace(go.Scatter(x=buys.index, y=buys['Close'], mode='markers', name="Buy Signal", marker=dict(symbol='triangle-up', size=15, color='green')))
        fig_f.add_trace(go.Scatter(x=sells.index, y=sells['Close'], mode='markers', name="Sell Signal", marker=dict(symbol='triangle-down', size=15, color='red')))
        st.plotly_chart(fig_f, use_container_width=True)
        

    # --- TAB 4: CREDIT RISK ---
    with tab4:
        st.title("Credit Risk: Structural Default Analysis")
        t_obj = yf.Ticker(sel_stock); bs = t_obj.balance_sheet; info = t_obj.info
        def get_d(keys):
            for k in keys:
                m = [i for i in bs.index if k.lower() in str(i).lower()]
                if m: return bs.loc[m[0]].iloc[0] / 1e7
            return 0.0
        st_d, lt_d = get_d(['Current Debt', 'Short Term Borrowings']), get_d(['Long Term Debt', 'Long Term Borrowings'])
        m_cap, tot_d = info.get('marketCap', 1e11)/1e7, info.get('totalDebt', 1e10)/1e7
        
        st.table(pd.DataFrame({"Component": ["ST Debt", "LT Debt", "Total Debt", "Market Cap"], "Value (Cr ‚Çπ)": [f"{st_d:,.2f}", f"{lt_d:,.2f}", f"{tot_d:,.2f}", f"{m_cap:,.2f}"]}))
        
        m_frame = st.radio("Model Framework", ["Merton Model", "KMV Model"])
        barr = (st_d + 0.5 * lt_d) if m_frame == "KMV Model" else tot_d
        barr = st.number_input("Final Default Barrier (Barrier Value)", value=float(barr) if barr > 0 else 5000.0)
        
        def solve_merton(E, se, L, r, T):
            def equations(p):
                V, sv = p; d1 = (np.log(V/L) + (r + 0.5 * sv**2) * T) / (sv * np.sqrt(T)); d2 = d1 - sv * np.sqrt(T)
                return [V * norm.cdf(d1) - L * np.exp(-r * T) * norm.cdf(d2) - E, (norm.cdf(d1) * V / E) * sv - se]
            return fsolve(equations, [E + L, se * (E / (E + L))])

        try:
            va, sa = solve_merton(m_cap, ann_vol, barr, rf_rate, 1.0)
            dd_val = (np.log(va/barr) + (rf_rate - 0.5 * sa**2)) / sa; pd_val = norm.cdf(-dd_val)
            
            c_cr1, c_cr2, c_cr3, c_cr4 = st.columns(4)
            c_cr1.metric("Distance to Default (DD)", f"{dd_val:.2f} œÉ")
            c_cr2.metric("Prob. of Default (PD)", f"{pd_val:.4%}")
            c_cr3.metric("Implied Asset Value (V)", f"‚Çπ{va:,.0f} Cr", help="Implied Market Value of total firm assets.")
            c_cr4.metric("Asset Volatility (œÉV)", f"{sa:.2%}", help="Implied Volatility of firm business assets.")
            
            st.divider()
            st.write(f"### **Structural Interpretation**")
            st.write(f"The model calculates an **Implied Asset Value of ‚Çπ{va:,.0f} Cr** with an asset-level risk of **{sa:.2%}**.")
            st.write(f"The firm is currently **{dd_val:.2f} standard deviations** from insolvency. A DD below 2.0œÉ signals high credit risk.")
        except: st.error("Model Solver Failure: Check balance sheet values.")
        

else: st.error("Data Load Error: Please check the Ticker and internet connection.")

