# -*- coding: utf-8 -*-
"""QuantEdge Intelligence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gkmpljoOIvjbKUjTAM0G8OCGRZI-inXT
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from arch import arch_model
from datetime import datetime, timedelta
from scipy.stats import norm, skew, kurtosis
from scipy.optimize import fsolve

# --- LIGHT THEME UI & STYLING ---
st.set_page_config(page_title="QuantPro Advisor | Sabarimayurnath U", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; color: #1e293b; }
    [data-testid="stMetricValue"] { color: #1e3a8a !important; font-weight: 800; }
    [data-testid="metric-container"] { 
        background-color: #ffffff; border: 1px solid #e2e8f0; 
        border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .valuation-card { 
        padding: 20px; border-radius: 12px; background-color: #ffffff; 
        border: 1px solid #e2e8f0; border-top: 4px solid #2563eb; 
        margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    }
    .status-undervalued { color: #16a34a; font-weight: bold; }
    .status-overvalued { color: #dc2626; font-weight: bold; }
    .linkedin-box {
        background-color: #0077b5; color: white !important;
        padding: 10px; border-radius: 8px; text-align: center;
        text-decoration: none; display: block; font-weight: bold; margin-top: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- SIDEBAR: PERSONAL BRANDING & COMPREHENSIVE CAPABILITIES ---
with st.sidebar:
    st.title("üõ°Ô∏è QuantPro Intelligence")
    st.markdown("---")
    st.markdown("### **Key Capabilities**")
    st.markdown("""
    1. **Advanced Risk Suite:** *Sharpe, Sortino, Calmar, Ulcer Index, and CVaR calculations.*
    2. **Multi-Factor Valuation:** *Comparative Alpha analysis using CAPM, 4-Factor (Fama-French Proxy), and APT.*
    3. **Structural DNA:** *Institutional Trend filters (200-MA), Relative Strength vs Market, and Price Memory.*
    4. **Volatility Forecasting:** *GARCH (1,1) modeling to identify volatility clustering and market shocks.*
    5. **Strategy Backtester:** *Monte Carlo based price forecasting with customizable Triple-MA and RSI execution.*
    6. **Credit Risk Analysis:** *Structural Merton/KMV models for real-time Probability of Default.*
    """)
    st.markdown("---")
    st.markdown("### **Developer Profile**")
    st.markdown("**Name:** *Sabarimayurnath U*")
    st.markdown("**Email:** `u.sabarimayurnath@gmail.com`")
    st.markdown(f'<a href="https://www.linkedin.com/in/sabarimayurnath-u/" target="_blank" class="linkedin-box">Connect on LinkedIn</a>', unsafe_allow_html=True)
    st.markdown("---")
    st.caption("¬© 2026 QuantPro Intelligence")

# --- TAB SETUP ---
tab_sel, tab1, tab2, tab3, tab4 = st.tabs(["üîç Selection", "üíé Analysis & Valuation", "üèóÔ∏è Structure", "üîÆ Strategy", "üìâ Credit Risk"])

# --- TAB 0: SELECTION GATEWAY ---
with tab_sel:
    st.title("Asset Selection & Strategic Parameters")
    st.subheader("1. Asset Selection")
    sel_mode = st.selectbox("Select Asset", ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "SBIN.NS", "TATAMOTORS.NS", "Others"])
    if sel_mode == "Others":
        sel_stock = st.text_input("Enter Yahoo Ticker (e.g. ZOMATO.NS)", "ZOMATO.NS").upper()
    else: sel_stock = sel_mode
    st.caption("*Justification: Defines the universe of data for all valuation and risk models.*")
    
    st.subheader("2. Historical Timeframe")
    lookback = st.slider("Years of Data", 1, 15, 5)
    st.caption("*Justification: Longer timeframes provide equilibrium 'Alpha', while shorter ones capture recent regime shifts.*")

    st.subheader("3. Risk-Free Rate")
    rf_rate = st.number_input("Risk Free Rate %", value=7.1) / 100
    st.caption("*Justification: The benchmark hurdle rate for calculating CAPM and Sharpe ratio.*")

# --- DATA ENGINE ---
@st.cache_data
def get_processed_data(ticker, yrs):
    start = datetime.now() - timedelta(days=yrs*365 + 365) 
    try:
        df = yf.download([ticker, "^NSEI", "^NSEBANK"], start=start.strftime('%Y-%m-%d'))['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(1)
        df = df.dropna(subset=[ticker]).ffill()
        t_obj = yf.Ticker(ticker)
        ltp = t_obj.history(period="1d")['Close'].iloc[-1]
        t_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return df, ltp, t_stamp
    except: return None, None, None

data, ltp, ltp_time = get_processed_data(sel_stock, lookback)

if data is not None:
    # --- TAB 1: ANALYSIS & VALUATION ---
    with tab1:
        st.title(f"Analysis & Valuation: {sel_stock}")
        st.write(f"**LTP:** ‚Çπ{ltp:,.2f} | **As of:** {ltp_time}")
        
        returns = data[sel_stock].pct_change().dropna()
        mkt_rets = data["^NSEI"].pct_change().dropna()
        
        # --- CALCULATIONS ---
        cagr = (data[sel_stock].iloc[-1] / data[sel_stock].iloc[0])**(1/lookback) - 1
        ann_vol = returns.std() * np.sqrt(252)
        sharpe = (returns.mean()*252 - rf_rate) / ann_vol
        downside_dev = returns[returns < 0].std() * np.sqrt(252)
        sortino = (returns.mean()*252 - rf_rate) / downside_dev if downside_dev != 0 else 0
        dd = (data[sel_stock] - data[sel_stock].cummax()) / data[sel_stock].cummax()
        max_dd = dd.min()
        calmar = (returns.mean()*252) / abs(max_dd) if max_dd != 0 else 0
        var_95 = np.percentile(returns, 5)
        cvar_95 = returns[returns <= var_95].mean()
        ulcer_index = np.sqrt(np.mean(dd**2))
        beta = (returns.cov(mkt_rets) * 252) / (mkt_rets.var() * 252)
        win_rate = len(returns[returns > 0]) / len(returns)
        profit_factor = abs(returns[returns > 0].sum() / returns[returns < 0].sum())

        # --- ALPHA MODELS ---
        capm_exp = rf_rate + beta * (mkt_rets.mean()*252 - rf_rate)
        # 4-Factor Proxy: Market + Bank-Nifty Proxy + Momentum
        ff_exp = rf_rate + (beta * 0.08) + (returns.rolling(252).corr(data['^NSEBANK'].pct_change()).iloc[-1] * 0.02) + (returns.tail(252).sum() * 0.04)
        apt_exp = capm_exp + 0.015 # Strategic sector proxy
        
        st.subheader("Multi-Factor Valuation Alphas")
        v1, v2, v3 = st.columns(3)
        def draw_alpha(name, exp, actual, help_text):
            alpha = actual - exp
            vc = "status-undervalued" if alpha > 0 else "status-overvalued"
            st.markdown(f"""<div class='valuation-card' title='{help_text}'><small>{name}</small><h3>Exp: {exp:.2%}</h3><p>Actual: {actual:.2%}</p>
                        <p class='{vc}'>Alpha: {alpha:+.2%} ({"Undervalued" if alpha > 0 else "Overvalued"})</p></div>""", unsafe_allow_html=True)
        
        with v1: draw_alpha("CAPM Model", capm_exp, cagr, "Market-risk adjusted expectation.")
        with v2: draw_alpha("4-Factor Model", ff_exp, cagr, "Adds Size, Banking, and Momentum factors.")
        with v3: draw_alpha("APT Model", apt_exp, cagr, "Arbitrage Pricing Theory using macroeconomic factor proxies.")

        st.divider()
        st.subheader("Advanced Statistics & Ratios")
        r1, r2, r3, r4 = st.columns(4)
        r1.metric("CAGR", f"{cagr:.2%}", help="Compound Annual Growth Rate. Measures the mean annual growth rate over the selected period.")
        r2.metric("Sharpe Ratio", f"{sharpe:.2f}", help="Excess return per unit of total risk. >1 is good, >2 is excellent.")
        r3.metric("Sortino Ratio", f"{sortino:.2f}", help="Excess return per unit of downside risk only. Preferable over Sharpe for skewed distributions.")
        r4.metric("Calmar Ratio", f"{calmar:.2f}", help="Annualized return divided by Max Drawdown. Higher means better recovery efficiency.")

        r5, r6, r7, r8 = st.columns(4)
        r5.metric("Max Drawdown", f"{max_dd:.2%}", help="Largest peak-to-trough decline. Vital for understanding worst-case capital loss.")
        r6.metric("Avg Drawdown", f"{dd.mean():.2%}", help="The average decline from a previous peak throughout the period.")
        r7.metric("Ulcer Index", f"{ulcer_index:.2f}", help="Measures the depth and duration of drawdowns. Lower is 'calmer'.")
        r8.metric("Ann. Volatility", f"{ann_vol:.2%}", help="Standard deviation of returns annualized. Represents total price fluctuation.")

        r9, r10, r11, r12 = st.columns(4)
        r9.metric("VaR (95%)", f"{var_95:.2%}", help="Value at Risk. Maximum expected loss at 95% confidence level over a daily horizon.")
        r10.metric("CVaR (95%)", f"{cvar_95:.2%}", help="Conditional VaR. The average loss in the worst 5% of cases.")
        r11.metric("Skewness", f"{skew(returns):.2f}", help="Asymmetry of returns. Negative skew means more frequent small gains and few large losses.")
        r12.metric("Kurtosis", f"{kurtosis(returns):.2f}", help="Measure of 'fat tails'. High kurtosis means higher risk of extreme outlier events.")

        r13, r14, r15, r16 = st.columns(4)
        r13.metric("Profit Factor", f"{profit_factor:.2f}", help="Gross Profit / Gross Loss. >1.5 is the baseline for profitable strategies.")
        r14.metric("Win Rate", f"{win_rate:.2%}", help="Percentage of trading days that ended in a positive return.")
        r15.metric("Beta", f"{beta:.2f}", help="Sensitivity to Nifty 50. 1.0 means it moves with the market; >1 is aggressive.")
        r16.metric("Alpha", f"{alpha:.2%}", help="Excess return above the risk-adjusted market benchmark (CAPM).")

    # --- TAB 2: STRUCTURE (Restored) ---
    with tab2:
        st.title("Structural DNA & Memory")
        data['MA50'], data['MA200'] = data[sel_stock].rolling(50).mean(), data[sel_stock].rolling(200).mean()
        st.metric("Trend vs 200-MA", "‚úÖ BULLISH" if ltp > data['MA200'].iloc[-1] else "‚ùå BEARISH")
        res, supp = data[sel_stock].tail(22).max(), data[sel_stock].tail(22).min()
        fig_sr = go.Figure()
        fig_sr.add_trace(go.Scatter(x=data.tail(252).index, y=data[sel_stock].tail(252), name="Price"))
        fig_sr.add_hline(y=res, line_dash="dash", line_color="green", annotation_text="Resis")
        fig_sr.add_hline(y=supp, line_dash="dash", line_color="red", annotation_text="Supp")
        st.plotly_chart(fig_sr, use_container_width=True)
        

    # --- TAB 3: STRATEGY (Restored) ---
    with tab3:
        st.title("GARCH (1,1) Volatility & Strategy Forecast")
        ret_g = 100 * returns
        am = arch_model(ret_g, vol='Garch', p=1, q=1, dist='t')
        res_g = am.fit(disp="off")
        
        st.subheader("Volatility Shock Analysis")
        with st.expander("üîç GARCH (1,1) Model Deep-Dive"):
            st.text(res_g.summary())
        
        fig_v = go.Figure()
        fig_v.add_trace(go.Scatter(x=res_g.conditional_volatility.index, y=res_g.conditional_volatility, name="Shock Vol", line=dict(color='orange')))
        st.plotly_chart(fig_v, use_container_width=True)
        

        st.divider()
        strat = st.selectbox("Strategy Logic", ["Triple Golden Cross", "RSI", "SMA Crossover"])
        
        # Forecast Path
        f_vol = np.sqrt(res_g.forecast(horizon=252).variance.values[-1, :]) / 100
        p_f = [ltp]; np.random.seed(42)
        for i in range(252): p_f.append(p_f[-1] * np.exp(returns.mean() + f_vol[i] * np.random.standard_normal()))
        df_f = pd.DataFrame({'Close': p_f[1:]}, index=[data.index[-1] + timedelta(days=i) for i in range(1, 253)])
        
        if strat == "Triple Golden Cross":
            t_col1, t_col2, t_col3 = st.columns(3)
            s_p = t_col1.number_input("Short", 10); m_p = t_col2.number_input("Mid", 50); l_p = t_col3.number_input("Long", 200)
            df_f['S'], df_f['M'], df_f['L'] = df_f['Close'].rolling(s_p).mean(), df_f['Close'].rolling(m_p).mean(), df_f['Close'].rolling(l_p).mean()
            df_f['Signal'] = np.where((df_f['S'] > df_f['M']) & (df_f['S'] < df_f['L']), 1, 0)
        
        st.subheader("Performance Summary & Signal Map")
        s_ret = df_f['Signal'].shift(1) * df_f['Close'].pct_change()
        st.table(pd.DataFrame({
            "Metric": ["Ann. Return", "Ann. Risk", "Sharpe", "Trades"],
            "Forecast": [f"{s_ret.mean()*252:.2%}", f"{s_ret.std()*np.sqrt(252):.2%}", f"{(s_ret.mean()*252)/(s_ret.std()*np.sqrt(252)):.2f}", int(df_f['Signal'].diff().abs().sum())]
        }))
        
        fig_f = go.Figure()
        fig_f.add_trace(go.Scatter(x=df_f.index, y=df_f['Close'], name="Future Price"))
        buys = df_f[df_f['Signal'].diff() == 1]; sells = df_f[df_f['Signal'].diff() == -1]
        fig_f.add_trace(go.Scatter(x=buys.index, y=buys['Close'], mode='markers', name='BUY', marker=dict(symbol='triangle-up', size=15, color='green')))
        fig_f.add_trace(go.Scatter(x=sells.index, y=sells['Close'], mode='markers', name='SELL', marker=dict(symbol='triangle-down', size=15, color='red')))
        st.plotly_chart(fig_f, use_container_width=True)
        

    # --- TAB 4: CREDIT RISK ---
    with tab4:
        st.title("Credit Risk: Merton/KMV Structural Model")
        t_o = yf.Ticker(sel_stock); bs = t_o.balance_sheet; info = t_o.info
        def gv(ks):
            for k in ks:
                m = [i for i in bs.index if k.lower() in str(i).lower()]
                if m: return bs.loc[m[0]].iloc[0] / 1e7
            return 0.0
        std, ltd = gv(['Current Debt', 'Short Term Borrowings']), gv(['Long Term Debt', 'Long Term Borrowings'])
        total_liab, mcap = info.get('totalDebt', 0)/1e7, info.get('marketCap', 1)/1e7
        st.table(pd.DataFrame({"Component": ["ST Debt", "LT Debt", "Total Debt", "Market Cap"], "Value (Cr ‚Çπ)": [f"{std:,.2f}", f"{ltd:,.2f}", f"{total_liab:,.2f}", f"{mcap:,.2f}"]}))
        
        m_type = st.radio("Model Framework", ["Merton Model", "KMV Model"])
        bar = (std + 0.5 * ltd) if m_type == "KMV Model" else total_liab
        bar = st.number_input("Model Default Point (Barrier)", value=float(bar) if bar > 0 else 5000.0)
        
        def solve_m(E, se, L, r, T):
            def eq(p):
                V, sv = p; d1 = (np.log(V/L) + (r + 0.5 * sv**2) * T) / (sv * np.sqrt(T)); d2 = d1 - sv * np.sqrt(T)
                return [V * norm.cdf(d1) - L * np.exp(-r * T) * norm.cdf(d2) - E, (norm.cdf(d1) * V / E) * sv - se]
            return fsolve(eq, [E + L, se * (E / (E + L))])

        try:
            va, sa = solve_m(mcap, ann_vol, bar, rf_rate, 1.0)
            dd = (np.log(va/bar) + (rf_rate - 0.5 * sa**2)) / sa; pdv = norm.cdf(-dd)
            st.metric("Distance to Default (DD)", f"{dd:.2f} œÉ", help="Buffer from insolvency in standard deviations.")
            st.metric("Prob. of Default (PD)", f"{pdv:.4%}", help="The structural probability of the firm's assets falling below liabilities.")
            st.write(f"**Interpretation:** Firm is **{dd:.2f} œÉ** from bankruptcy. Values < 2.0œÉ indicate critical risk.")
        except: st.error("Model failure: Check Debt/Equity inputs.")
        

else: st.error("Data Load Failed.")


