# -*- coding: utf-8 -*-
"""QuantEdge Intelligence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gkmpljoOIvjbKUjTAM0G8OCGRZI-inXT
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from arch import arch_model
from datetime import datetime, timedelta
from scipy.stats import norm, skew, kurtosis, probplot
from scipy.optimize import fsolve

# --- LIGHT THEME UI & STYLING ---
st.set_page_config(page_title="Sabarimayur's 360¬∞ Stock Strategy & Valuation Suite", layout="wide", page_icon="üõ°Ô∏è")

st.markdown("""
<style>
    .stApp { background-color: #f8fafc; color: #1e293b; }
    [data-testid="stMetricValue"] { color: #1e3a8a !important; font-weight: 800; }
    [data-testid="metric-container"] {
        background-color: #ffffff; border: 1px solid #e2e8f0;
        border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .valuation-card {
        padding: 20px; border-radius: 12px; background-color: #ffffff;
        border: 1px solid #e2e8f0; border-top: 4px solid #2563eb;
        margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    }
    .status-undervalued { color: #16a34a; font-weight: bold; }
    .status-overvalued { color: #dc2626; font-weight: bold; }
    .linkedin-box {
        background-color: #0077b5; color: white !important;
        padding: 12px; border-radius: 8px; text-align: center;
        text-decoration: none; display: block; font-weight: bold; margin-top: 15px;
    }
</style>
""", unsafe_allow_html=True)

# --- SIDEBAR: PERSONAL BRANDING & COMPREHENSIVE CAPABILITIES ---
with st.sidebar:
    st.title(" üõ°Ô∏è  QuantPro Intelligence")
    st.markdown("---")
    st.markdown("### **Key Capabilities**")
    st.markdown("""
    * **Advanced Risk Suite:** *Sharpe, Sortino, Calmar, Ulcer Index, and CVaR.*
    * **Multi-Factor Valuation:** *Alpha analysis using CAPM, 4-Factor, and APT.*
    * **Structural DNA:** *200-MA filters, Support/Resistance & Relative Strength.*
    * **Volatility Forecasting:** *GARCH (1,1) modeling & News Impact Curve.*
    * **Strategy Backtester:** *Customizable Triple-MA and RSI execution.*
    * **Market Risk:** *Rolling Beta, QQ Plots, & Stress Testing.*
    * **Credit Risk Analysis:** *Merton/KMV models for Probability of Default.*
    * **Comparison:** *Multi-stock Ranking & Winner Logic.*
    """)
    st.markdown("---")
    st.markdown("### **Developer Profile**")
    st.markdown("**Name:** *Sabarimayurnath U*")
    st.markdown("**Email:** `u.sabarimayurnath@gmail.com`")
    st.markdown(f'<a href="https://www.linkedin.com/in/sabarimayurnath-u/" target="_blank" class="linkedin-box">Connect on LinkedIn</a>', unsafe_allow_html=True)
    st.markdown("---")
    st.caption("¬© 2026 QuantPro Intelligence")

# --- DATA HELPERS ---
@st.cache_data(ttl=3600)
def get_full_consolidated_data(ticker, yrs):
    start = datetime.now() - timedelta(days=yrs*365 + 365)
    try:
        # 1. Price History
        df = yf.download([ticker, "^NSEI", "^NSEBANK"], start=start.strftime('%Y-%m-%d'), progress=False)['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        # Ensure columns are correct after MultiIndex handling
        cols = [c for c in df.columns if ticker in c]
        if not cols: return None 
        
        # Depending on yfinance version, columns might be different, let's standardize
        # We need the specific ticker, NSEI and NSEBANK
        # For simplicity in this logic, we assume standard download structure
        
        df = df.dropna().ffill()

        # 2. Fundamental Snapshot
        t_obj = yf.Ticker(ticker)
        info = t_obj.info
        bs = t_obj.balance_sheet

        # LTP & Timing
        ltp = df[ticker].iloc[-1]
        t_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # Debt Logic (Fuzzy)
        def get_debt_val(labels):
            for label in labels:
                match = [i for i in bs.index if label.lower() in str(i).lower()]
                if match: return bs.loc[match[0]].iloc[0] / 1e7
            return 0.0

        return {
            "df": df, "ltp": ltp, "time": t_stamp,
            "market_cap": info.get('marketCap', 0) / 1e7,
            "total_debt": info.get('totalDebt', 0) / 1e7,
            "st_debt": get_debt_val(['Current Debt', 'Short Term Borrowings']),
            "lt_debt": get_debt_val(['Long Term Debt', 'Long Term Borrowings'])
        }
    except Exception as e:
        return None

# Helper for Comparison Tab
def get_simple_data(ticker, start_date):
    try:
        data = yf.download(ticker, start=start_date, progress=False)
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(0)
        return data
    except:
        return pd.DataFrame()

def calculate_comp_metrics(df):
    if df.empty: return {}
    last_price = df['Close'].iloc[-1]
    daily_ret = df['Close'].pct_change().dropna()
    days = (df.index[-1] - df.index[0]).days
    cagr = ((df['Close'].iloc[-1] / df['Close'].iloc[0]) ** (365/days)) - 1
    volatility = daily_ret.std() * np.sqrt(252)
    sharpe = (daily_ret.mean() / daily_ret.std()) * np.sqrt(252)
    cumulative = (1 + daily_ret).cumprod()
    peak = cumulative.cummax()
    drawdown = (cumulative - peak) / peak
    max_drawdown = drawdown.min()
    return {
        "Price": last_price, "CAGR %": cagr * 100, "Volatility %": volatility * 100,
        "Sharpe": sharpe, "Max Drawdown %": max_drawdown * 100
    }

# --- TAB SETUP ---
tab_sel, tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    " üîç Selection", 
    " üíé Analysis & Valuation", 
    " üèóÔ∏è Structure", 
    " üîÆ Strategy", 
    " ‚ö†Ô∏è Market Risk", 
    " üìâ Credit Risk",
    " ‚öñÔ∏è Comparison"
])

# --- TAB 0: SELECTION GATEWAY ---
with tab_sel:
    st.title("Asset Selection & Strategic Parameters")
    st.subheader("1. Asset Selection")
    sel_mode = st.selectbox("Select Asset", ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "SBIN.NS", "TATAMOTORS.NS", "Others"])
    if sel_mode == "Others":
        sel_stock = st.text_input("Enter Yahoo Ticker (e.g. ETERNAL.NS)", "ETERNAL.NS").upper()
    else: sel_stock = sel_mode
    st.caption("*Justification: Defines the universe of data for all valuation and risk models.*")

    st.subheader("2. Historical Timeframe")
    lookback_yrs = st.slider("Years of Data", 1, 15, 5)
    
    st.subheader("3. Risk-Free Rate")
    rf_rate_input = st.number_input("Risk Free Rate %", value=7.1)
    rf_rate = rf_rate_input / 100

# --- MAIN LOGIC ---
res = get_full_consolidated_data(sel_stock, lookback_yrs)

if res is not None:
    data = res["df"]
    # Ensure columns exist
    if sel_stock in data.columns and "^NSEI" in data.columns:
        returns = data[sel_stock].pct_change().dropna()
        mkt_rets = data["^NSEI"].pct_change().dropna()
        
        # Align dates
        common_idx = returns.index.intersection(mkt_rets.index)
        returns = returns.loc[common_idx]
        mkt_rets = mkt_rets.loc[common_idx]

        ann_ret_raw = returns.mean() * 252
        ann_vol = returns.std() * np.sqrt(252)
        cagr = (data[sel_stock].iloc[-1] / data[sel_stock].iloc[0])**(1/lookback_yrs) - 1

        # --- TAB 1: ANALYSIS & VALUATION ---
        with tab1:
            st.title(f"Analysis & Valuation: {sel_stock}")
            st.write(f"**Last Traded Price (LTP):** ‚Çπ{res['ltp']:,.2f} | **As of:** {res['time']}")

            # Risk Metrics
            sharpe = (ann_ret_raw - rf_rate) / ann_vol
            downside_dev = returns[returns < 0].std() * np.sqrt(252)
            sortino = (ann_ret_raw - rf_rate) / downside_dev if downside_dev != 0 else 0
            dd = (data[sel_stock] - data[sel_stock].cummax()) / data[sel_stock].cummax()
            calmar = ann_ret_raw / abs(dd.min()) if dd.min() != 0 else 0

            # Valuation Models
            beta = (returns.cov(mkt_rets) * 252) / (mkt_rets.var() * 252)
            capm_exp = rf_rate + beta * (mkt_rets.mean()*252 - rf_rate)
            
            # 4-Factor Proxy (Market, Momentum, Sector)
            if "^NSEBANK" in data.columns:
                bank_ret = data['^NSEBANK'].pct_change().dropna()
                idx_common = returns.index.intersection(bank_ret.index)
                sec_corr = returns.loc[idx_common].rolling(252).corr(bank_ret.loc[idx_common]).iloc[-1]
            else:
                sec_corr = 0.5
                
            ff_exp = rf_rate + (beta * 0.08) + (sec_corr * 0.02)
            apt_exp = capm_exp + 0.015

            st.subheader("Multi-Factor Valuation Alphas")
            v1, v2, v3 = st.columns(3)
            def draw_v(col, name, exp, actual, help_t):
                al = actual - exp
                vc = "status-undervalued" if al > 0 else "status-overvalued"
                col.markdown(f"""<div class='valuation-card' title='{help_t}'><small>{name}</small><h3>Exp: {exp:.2%}</h3>
                <p class='{vc}'>Alpha: {al:+.2%} ({"Undervalued" if al > 0 else "Overvalued"})</p></div>""", unsafe_allow_html=True)
            
            draw_v(v1, "CAPM Model", capm_exp, cagr, "Market Risk adjusted.")
            draw_v(v2, "4-Factor Model", ff_exp, cagr, "Market, Sector, & Momentum.")
            draw_v(v3, "APT Model", apt_exp, cagr, "Macroeconomic factor proxy.")

            st.divider()
            st.subheader("16-Point Advanced Statistics & Ratios")
            r_cols = st.columns(4)
            r_cols[0].metric("Sharpe Ratio", f"{sharpe:.2f}")
            r_cols[1].metric("Sortino Ratio", f"{sortino:.2f}")
            r_cols[2].metric("Calmar Ratio", f"{calmar:.2f}")
            r_cols[3].metric("CAGR", f"{cagr:.2%}")
            
            r_cols2 = st.columns(4)
            r_cols2[0].metric("Max Drawdown", f"{dd.min():.2%}")
            r_cols2[1].metric("Avg Drawdown", f"{dd.mean():.2%}")
            r_cols2[2].metric("Ulcer Index", f"{np.sqrt(np.mean(dd**2)):.2f}")
            r_cols2[3].metric("Ann. Volatility", f"{ann_vol:.2%}")

            r_cols3 = st.columns(4)
            r_cols3[0].metric("Downside Deviation", f"{downside_dev:.2%}")
            r_cols3[1].metric("VaR (95%)", f"{np.percentile(returns, 5):.2%}")
            r_cols3[2].metric("CVaR (95%)", f"{returns[returns <= np.percentile(returns, 5)].mean():.2%}")
            r_cols3[3].metric("Skewness", f"{skew(returns):.2f}")

            r_cols4 = st.columns(4)
            r_cols4[0].metric("Kurtosis", f"{kurtosis(returns):.2f}")
            r_cols4[1].metric("Win Rate", f"{len(returns[returns > 0])/len(returns):.2%}")
            r_cols4[2].metric("Profit Factor", f"{abs(returns[returns > 0].sum() / returns[returns < 0].sum()):.2f}")
            r_cols4[3].metric("Gain-to-Pain", f"{returns.sum()/abs(returns[returns < 0].sum()):.2f}")

        # --- TAB 2: STRUCTURE ---
        with tab2:
            st.title("Structural DNA & Interpretation")
            data['MA50'] = data[sel_stock].rolling(50).mean()
            data['MA200'] = data[sel_stock].rolling(200).mean()

            c_tr1, c_tr2, c_tr3 = st.columns(3)
            with c_tr1:
                st.metric("Trend vs 200-MA", " ‚úÖ BULLISH" if res['ltp'] > data['MA200'].iloc[-1] else " ‚ùå BEARISH")
                st.write("**Interpretation:** The 200-day MA is the institutional line.")
            with c_tr2:
                st.metric("50/200 MA Cross", " üî• GOLDEN" if data['MA50'].iloc[-1] > data['MA200'].iloc[-1] else " ‚ùÑÔ∏è DEATH")
                st.write("**Interpretation:** Golden Cross signals major momentum shift.")
            with c_tr3:
                st.metric("Dist. 52W High", f"{((res['ltp'] / data[sel_stock].max())-1):.2%}")
                st.write("**Interpretation:** Measures proximity to peak.")

            res_sr, supp_sr = data[sel_stock].tail(22).max(), data[sel_stock].tail(22).min()
            st.subheader("Price Memory Chart")
            fig_sr = go.Figure()
            fig_sr.add_trace(go.Scatter(x=data.tail(252).index, y=data[sel_stock].tail(252), name="Price"))
            fig_sr.add_hline(y=res_sr, line_dash="dash", line_color="green", annotation_text="Resis")
            fig_sr.add_hline(y=supp_sr, line_dash="dash", line_color="red", annotation_text="Supp")
            st.plotly_chart(fig_sr, use_container_width=True)

        # --- TAB 3: STRATEGY ---
        with tab3:
            st.title("GARCH (1,1) Volatility & Strategy")
            ret_g = 100 * returns
            am = arch_model(ret_g, vol='Garch', p=1, q=1, dist='t')
            res_g = am.fit(disp="off")

            st.subheader("Volatility Engine Status")
            mv1, mv2 = st.columns(2)
            mv1.metric("Current Volatility Shock", f"{res_g.conditional_volatility.iloc[-1]:.2f}")
            mv2.metric("Volatility Persistence (Beta)", f"{res_g.params['beta[1]']:.3f}")

            # 1. Volatility Plot
            st.markdown("#### Conditional Volatility History")
            fig_v = go.Figure()
            fig_v.add_trace(go.Scatter(x=res_g.conditional_volatility.index, y=res_g.conditional_volatility, name="Predicted Vol", line=dict(color='orange')))
            st.plotly_chart(fig_v, use_container_width=True)
            
            # 2. News Impact Curve (NEW INTEGRATION)
            st.markdown("#### News Impact Curve (NIC)")
            params = res_g.params
            uncond_var = res_g.conditional_volatility.var() 
            epsilon_range = np.linspace(ret_g.min(), ret_g.max(), 100)
            nic_sigma2 = params['omega'] + params['alpha[1]'] * (epsilon_range**2) + params['beta[1]'] * uncond_var
            
            fig_nic = go.Figure()
            fig_nic.add_trace(go.Scatter(x=epsilon_range, y=nic_sigma2, mode='lines', line=dict(color='firebrick')))
            fig_nic.update_layout(title="News Impact Curve", xaxis_title="Shock (Œµ)", yaxis_title="Conditional Variance (œÉ¬≤)")
            st.plotly_chart(fig_nic, use_container_width=True)

            st.divider()
            st.subheader("Strategy Backtester (1-Year Forecast)")
            strat_choice = st.selectbox("Strategy Methodology", ["Triple Golden Cross", "RSI", "SMA Crossover"])

            # Forecast Simulation
            f_vol = np.sqrt(res_g.forecast(horizon=252).variance.values[-1, :]) / 100
            p_f = [res['ltp']]; np.random.seed(42)
            for i in range(252): p_f.append(p_f[-1] * np.exp(returns.mean() + f_vol[i] * np.random.standard_normal()))
            df_f = pd.DataFrame({'Close': p_f[1:]}, index=[data.index[-1] + timedelta(days=i) for i in range(1, 253)])

            if strat_choice == "Triple Golden Cross":
                tc1, tc2, tc3 = st.columns(3)
                s_p = tc1.number_input("Short MA", 10); m_p = tc2.number_input("Mid MA", 50); l_p = tc3.number_input("Long MA", 200)
                df_f['S'], df_f['M'], df_f['L'] = df_f['Close'].rolling(s_p).mean(), df_f['Close'].rolling(m_p).mean(), df_f['Close'].rolling(l_p).mean()
                df_f['Signal'] = np.where((df_f['S'] > df_f['M']) & (df_f['S'] < df_f['L']), 1, 0)
            elif strat_choice == "RSI":
                r_p = st.slider("RSI Period", 7, 30, 14)
                delta = df_f['Close'].diff(); g = delta.where(delta > 0, 0).rolling(r_p).mean(); l = -delta.where(delta < 0, 0).rolling(r_p).mean()
                df_f['RSI'] = 100 - (100 / (1 + (g/l))); df_f['Signal'] = np.where(df_f['RSI'] < 30, 1, 0)
            else:
                df_f['Signal'] = np.where(df_f['Close'].rolling(20).mean() > df_f['Close'].rolling(50).mean(), 1, 0)
            
            s_ret_fore = df_f['Signal'].shift(1) * df_f['Close'].pct_change()
            st.table(pd.DataFrame({
                "Metric": ["Annualized Return", "Annualized Risk", "Sharpe Value", "No. of Trades"],
                "Value": [f"{s_ret_fore.mean()*252:.2%}", f"{s_ret_fore.std()*np.sqrt(252):.2%}", f"{(s_ret_fore.mean()*252)/(s_ret_fore.std()*np.sqrt(252)) if s_ret_fore.std()!=0 else 0:.2f}", int(df_f['Signal'].diff().abs().sum())]
            }))
            
            fig_f = go.Figure()
            fig_f.add_trace(go.Scatter(x=df_f.index, y=df_f['Close'], name="Forecast Price"))
            buys = df_f[df_f['Signal'].diff() == 1]; sells = df_f[df_f['Signal'].diff() == -1]
            fig_f.add_trace(go.Scatter(x=buys.index, y=buys['Close'], mode='markers', name="Buy", marker=dict(symbol='triangle-up', size=15, color='green')))
            fig_f.add_trace(go.Scatter(x=sells.index, y=sells['Close'], mode='markers', name="Sell", marker=dict(symbol='triangle-down', size=15, color='red')))
            st.plotly_chart(fig_f, use_container_width=True)

        # --- TAB 5: MARKET RISK (NEW INTEGRATION) ---
        with tab5:
            st.title("‚ö†Ô∏è Market Risk Analysis")
            
            # 1. Rolling Beta
            st.subheader("Rolling Beta (vs Nifty 50)")
            roll_cov = returns.rolling(60).cov(mkt_rets)
            roll_var = mkt_rets.rolling(60).var()
            rolling_beta = roll_cov / roll_var
            
            fig_beta = go.Figure()
            fig_beta.add_trace(go.Scatter(x=rolling_beta.index, y=rolling_beta, mode='lines', name='60-Day Beta', line=dict(color='purple')))
            fig_beta.add_hline(y=1, line_dash="dot", line_color="black")
            st.plotly_chart(fig_beta, use_container_width=True)

            col_mr1, col_mr2 = st.columns(2)
            with col_mr1:
                # 2. Historical VaR
                st.subheader("Historical VaR (Rolling)")
                rolling_var = returns.rolling(30).quantile(0.05)
                fig_rvar = go.Figure()
                fig_rvar.add_trace(go.Scatter(x=rolling_var.index, y=rolling_var, fill='tozeroy', line=dict(color='firebrick'), name='95% VaR'))
                st.plotly_chart(fig_rvar, use_container_width=True)
            
            with col_mr2:
                # 3. QQ Plot
                st.subheader("QQ Plot (Normality Test)")
                qq_data = probplot(returns, dist="norm")
                fig_qq = px.scatter(x=qq_data[0][0], y=qq_data[0][1], labels={'x': 'Theoretical', 'y': 'Sample'})
                slope, intercept, r = qq_data[1]
                line_x = np.array([min(qq_data[0][0]), max(qq_data[0][0])])
                line_y = slope * line_x + intercept
                fig_qq.add_trace(go.Scatter(x=line_x, y=line_y, mode='lines', name='Fit', line=dict(color='red')))
                st.plotly_chart(fig_qq, use_container_width=True)

            # 4. Stress Testing
            st.subheader("üí• Stress Testing (Hypothetical Loss)")
            current_capital = st.number_input("Portfolio Value (‚Çπ)", value=100000)
            scenarios = {"Mild (-10%)": -0.10, "Bear (-20%)": -0.20, "Crash (-30%)": -0.30, "Crisis (-50%)": -0.50}
            loss_data = [{"Scenario": k, "Projected Value": current_capital * (1+v), "Loss": current_capital * v} for k, v in scenarios.items()]
            fig_stress = px.bar(pd.DataFrame(loss_data), x="Scenario", y="Loss", text="Loss", title="P&L Impact", color="Loss", color_continuous_scale="Reds_r")
            st.plotly_chart(fig_stress, use_container_width=True)

        # --- TAB 6: CREDIT RISK ---
        with tab4:
            st.title("Credit Risk: Merton/KMV Structural Default Model")
            st.table(pd.DataFrame({"Component": ["ST Debt", "LT Debt", "Total Debt", "Market Cap"],
            "Value (Cr ‚Çπ)": [f"{res['st_debt']:,.2f}", f"{res['lt_debt']:,.2f}", f"{res['total_debt']:,.2f}", f"{res['market_cap']:,.2f}"]}))

            m_frame = st.radio("Model Framework", ["Merton Model", "KMV Model"])
            barr = (res['st_debt'] + 0.5 * res['lt_debt']) if m_frame == "KMV Model" else res['total_debt']
            barr = st.number_input("Final Default Barrier (Threshold)", value=float(barr) if barr > 0 else 5000.0)

            def solve_m(E, se, L, r, T):
                def eq(p):
                    V, sv = p; d1 = (np.log(V/L) + (r + 0.5 * sv**2) * T) / (sv * np.sqrt(T));
                    d2 = d1 - sv * np.sqrt(T)
                    return [V * norm.cdf(d1) - L * np.exp(-r * T) * norm.cdf(d2) - E, (norm.cdf(d1) * V / E) * sv - se]
                return fsolve(eq, [E + L, se * (E / (E + L))])
            
            try:
                va, sa = solve_m(res['market_cap'], ann_vol, barr, rf_rate, 1.0)
                dd_v = (np.log(va/barr) + (rf_rate - 0.5 * sa**2)) / sa; pd_v = norm.cdf(-dd_v)
                c_c1, c_c2, c_c3, c_c4 = st.columns(4)
                c_c1.metric("Distance to Default", f"{dd_v:.2f} œÉ")
                c_c2.metric("Prob. of Default", f"{pd_v:.4%}")
                c_c3.metric("Asset Value (V)", f"‚Çπ{va:,.0f} Cr")
                c_c4.metric("Asset Volatility (œÉV)", f"{sa:.2%}")
                
                st.divider()
                st.write(f"**Interpretation:** The firm is **{dd_v:.2f} œÉ** from default. < 1.5œÉ indicates distress.")
            except: st.error("Solver Error: Debt/Equity ratio extreme.")

    # --- TAB 7: COMPARISON (NEW INTEGRATION) ---
    with tab6:
        st.title("‚öñÔ∏è Multi-Stock Comparison")
        comp_tickers = st.text_input("Enter Tickers (comma separated)", "RELIANCE.NS, TCS.NS, INFY.NS, HDFCBANK.NS")
        if st.button("Run Comparison"):
            tickers_list = [t.strip() for t in comp_tickers.split(',')]
            comp_data = []
            
            start_comp = datetime.now() - timedelta(days=lookback_yrs*365)
            
            for t in tickers_list:
                d = get_simple_data(t, start_comp)
                if not d.empty:
                    m = calculate_comp_metrics(d)
                    m['Ticker'] = t
                    comp_data.append(m)
            
            if comp_data:
                df_comp = pd.DataFrame(comp_data).set_index('Ticker')
                
                # Winner Logic
                best_row = {}
                for col in df_comp.columns:
                    if col in ["Volatility %", "Max Drawdown %"]:
                        # Lower is better
                        best_val = df_comp[col].min()
                        best_ticker = df_comp[col].idxmin()
                    else:
                        # Higher is better
                        best_val = df_comp[col].max()
                        best_ticker = df_comp[col].idxmax()
                    best_row[col] = f"{best_ticker} ({best_val:.2f})"
                
                df_comp_display = df_comp.copy()
                df_comp_display.loc['üèÜ WINNER'] = pd.Series(best_row)
                
                st.subheader("Performance Matrix")
                st.table(df_comp_display)
                
                st.subheader("Normalized Return Chart")
                norm_df = pd.DataFrame()
                for t in tickers_list:
                    d = get_simple_data(t, start_comp)
                    if not d.empty:
                        norm_df[t] = (d['Close'] / d['Close'].iloc[0]) * 100
                st.line_chart(norm_df)

else:
    st.error("Error loading data. Please check the ticker.")



