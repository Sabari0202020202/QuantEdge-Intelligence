# -*- coding: utf-8 -*-
"""QuantEdge Intelligence

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gkmpljoOIvjbKUjTAM0G8OCGRZI-inXT
"""

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from arch import arch_model
from datetime import datetime, timedelta
from scipy.stats import norm, skew, kurtosis
from scipy.optimize import fsolve

# --- LIGHT THEME UI & STYLING ---
st.set_page_config(page_title="Sabarimayur's 360¬∞ Stock Strategy & Valuation Suite", layout="wide")
st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; color: #1e293b; }
    [data-testid="stMetricValue"] { color: #1e3a8a !important; font-weight: 800; }
    [data-testid="metric-container"] { 
        background-color: #ffffff; border: 1px solid #e2e8f0; 
        border-radius: 12px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .valuation-card { 
        padding: 20px; border-radius: 12px; background-color: #ffffff; 
        border: 1px solid #e2e8f0; border-top: 4px solid #2563eb; 
        margin-bottom: 15px; box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    }
    .status-undervalued { color: #16a34a; font-weight: bold; }
    .status-overvalued { color: #dc2626; font-weight: bold; }
    .linkedin-box {
        background-color: #0077b5; color: white !important;
        padding: 10px; border-radius: 8px; text-align: center;
        text-decoration: none; display: block; font-weight: bold; margin-top: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

# --- SIDEBAR: PERSONAL BRANDING & KEY CAPABILITIES ---
with st.sidebar:
    st.title("üõ°Ô∏è 360¬∞ Stock Strategy & Valuation Suite")
    st.markdown("---")
    st.markdown("### **Key Capabilities**")
    st.markdown("""
    1. **Advanced Risk Suite:** *Sharpe, Sortino, Calmar, Ulcer Index, and CVaR calculations.*
    2. **Multi-Factor Valuation:** *Comparative Alpha analysis using CAPM, 4-Factor, and APT.*
    3. **Structural DNA:** *Institutional Trend filters (200-MA) and Support/Resistance memory.*
    4. **Volatility Forecasting:** *GARCH (1,1) modeling for risk regimes.*
    5. **Strategy Backtester:** *Customizable Triple-MA and RSI execution.*
    6. **Credit Risk Analysis:** *Merton/KMV models for Probability of Default.*
    """)
    st.markdown("---")
    st.markdown("### **Developer Profile**")
    st.markdown("**Name:** *Sabarimayurnath U*")
    st.markdown("**Email:** `u.sabarimayurnath@gmail.com`")
    st.markdown(f'<a href="https://www.linkedin.com/in/sabarimayurnath-u/" target="_blank" class="linkedin-box">Connect on LinkedIn</a>', unsafe_allow_html=True)
    st.markdown("---")
    st.caption("¬© 2026 QuantPro Intelligence")

# --- TAB SETUP ---
tab_sel, tab1, tab2, tab3, tab4 = st.tabs(["üîç Selection", "üíé Analysis & Valuation", "üèóÔ∏è Structure", "üîÆ Strategy", "üìâ Credit Risk"])

# --- TAB 0: SELECTION GATEWAY ---
with tab_sel:
    st.title("Asset Selection & Strategic Parameters")
    st.subheader("1. Asset Selection")
    sel_mode = st.selectbox("Select Asset", ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "SBIN.NS", "TATAMOTORS.NS", "Others"])
    if sel_mode == "Others":
        sel_stock = st.text_input("Enter Yahoo Ticker (e.g. ZOMATO.NS)", "ZOMATO.NS").upper()
    else: sel_stock = sel_mode
    st.caption("*Justification: Defines the universe of data for all valuation and risk models.*")
    
    st.subheader("2. Historical Timeframe")
    lookback_yrs = st.slider("Years of Data", 1, 15, 5)
    st.caption("*Justification: Longer timeframes provide equilibrium 'Alpha', while shorter ones capture recent regime shifts.*")

    st.subheader("3. Risk-Free Rate")
    rf_rate_input = st.number_input("Risk Free Rate %", value=7.1)
    rf_rate = rf_rate_input / 100
    st.caption("*Justification: The benchmark hurdle rate for calculating CAPM and Sharpe ratio.*")

# --- DATA ENGINE (Consolidated to avoid Rate Limits) ---
@st.cache_data(ttl=3600)
def get_consolidated_data(ticker, yrs):
    start = datetime.now() - timedelta(days=yrs*365 + 365) 
    try:
        df = yf.download([ticker, "^NSEI", "^NSEBANK"], start=start.strftime('%Y-%m-%d'), progress=False)['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(1)
        df = df.dropna(subset=[ticker]).ffill()
        
        t_obj = yf.Ticker(ticker)
        info = t_obj.info
        bs = t_obj.balance_sheet
        
        ltp = df[ticker].iloc[-1]
        t_stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        def get_d(keys):
            for k in keys:
                m = [i for i in bs.index if k.lower() in str(i).lower()]
                if m: return bs.loc[m[0]].iloc[0] / 1e7
            return 0.0
        
        std, ltd = get_d(['Current Debt', 'Short Term']), get_d(['Long Term'])
        mcap, tot_d = info.get('marketCap', 1e11)/1e7, info.get('totalDebt', 1e10)/1e7
        
        return {"df": df, "ltp": ltp, "time": t_stamp, "mcap": mcap, "total_d": tot_d, "st_d": std, "lt_d": ltd}
    except: return None

res = get_consolidated_data(sel_stock, lookback_yrs)

if res is not None:
    data = res["df"]
    returns = data[sel_stock].pct_change().dropna()
    mkt_rets = data["^NSEI"].pct_change().dropna()
    ann_ret_raw = returns.mean() * 252
    ann_vol = returns.std() * np.sqrt(252)
    cagr = (data[sel_stock].iloc[-1] / data[sel_stock].iloc[0])**(1/lookback_yrs) - 1

    # --- TAB 1: ANALYSIS & VALUATION ---
    with tab1:
        st.title(f"Analysis & Valuation: {sel_stock}")
        st.write(f"**LTP:** ‚Çπ{res['ltp']:,.2f} | **As of:** {res['time']}")
        
        # Alpha Models
        beta = (returns.cov(mkt_rets) * 252) / (mkt_rets.var() * 252)
        capm_exp = rf_rate + beta * (mkt_rets.mean()*252 - rf_rate)
        ff_exp = rf_rate + (beta * 0.08) + (returns.rolling(252).corr(data['^NSEBANK'].pct_change()).iloc[-1] * 0.02)
        apt_exp = capm_exp + 0.015

        st.subheader("Multi-Factor Valuation Alphas")
        v_cols = st.columns(3)
        def draw_v(col, name, exp, actual, help_t):
            al = actual - exp
            vc = "status-undervalued" if al > 0 else "status-overvalued"
            col.markdown(f"""<div class='valuation-card' title='{help_t}'><small>{name}</small><h3>Exp: {exp:.2%}</h3>
                        <p class='{vc}'>Alpha: {al:+.2%} ({"Undervalued" if al > 0 else "Overvalued"})</p></div>""", unsafe_allow_html=True)
        draw_v(v_cols[0], "CAPM Model", capm_exp, cagr, "Market-risk adjusted baseline.")
        draw_v(v_cols[1], "4-Factor Model", ff_exp, cagr, "Market + Size + Momentum proxies.")
        draw_v(v_cols[2], "APT Model", apt_exp, cagr, "Sector specific macro-proxy.")

        st.divider()
        st.subheader("19-Point Advanced Statistics & Ratios")
        sharpe = (ann_ret_raw - rf_rate) / ann_vol
        sortino = (ann_ret_raw - rf_rate) / (returns[returns < 0].std() * np.sqrt(252))
        dd = (data[sel_stock] - data[sel_stock].cummax()) / data[sel_stock].cummax()
        
        r1, r2, r3, r4 = st.columns(4)
        r1.metric("CAGR", f"{cagr:.2%}", help="Compound Annual Growth Rate.")
        r2.metric("Sharpe Ratio", f"{sharpe:.2f}", help="Return per unit of total risk.")
        r3.metric("Sortino Ratio", f"{sortino:.2f}", help="Return per unit of downside risk.")
        r4.metric("Calmar Ratio", f"{(ann_ret_raw/abs(dd.min())):.2f}", help="Return vs Max Drawdown.")

        r5, r6, r7, r8 = st.columns(4)
        r5.metric("Max Drawdown", f"{dd.min():.2%}", help="Worst peak-to-trough drop.")
        r6.metric("Avg Drawdown", f"{dd.mean():.2%}", help="Average drop from peaks.")
        r7.metric("Ulcer Index", f"{np.sqrt(np.mean(dd**2)):.2f}", help="Measure of drawdown stress.")
        r8.metric("Ann. Volatility", f"{ann_vol:.2%}", help="Annualized Standard Deviation.")

        r9, r10, r11, r12 = st.columns(4)
        r9.metric("VaR (95%)", f"{np.percentile(returns, 5):.2%}", help="Value at Risk (Daily).")
        r10.metric("CVaR (95%)", f"{returns[returns <= np.percentile(returns, 5)].mean():.2%}", help="Expected Shortfall.")
        r11.metric("Skewness", f"{skew(returns):.2f}", help="Asymmetry of returns.")
        r12.metric("Kurtosis", f"{kurtosis(returns):.2f}", help="Fat-tail risk.")

        r13, r14, r15, r16 = st.columns(4)
        r13.metric("Profit Factor", f"{abs(returns[returns > 0].sum() / returns[returns < 0].sum()):.2f}", help="Gross Profit / Gross Loss.")
        r14.metric("Win Rate", f"{len(returns[returns > 0])/len(returns):.2%}", help="Positive return days.")
        r15.metric("Beta", f"{beta:.2f}", help="Market sensitivity.")
        r16.metric("Alpha (CAPM)", f"{(ann_ret_raw - capm_exp):.2%}", help="Active return over CAPM.")

    # --- TAB 2: STRUCTURE ---
    with tab2:
        st.title("Structural DNA & Trend Analysis")
        data['MA50'], data['MA200'] = data[sel_stock].rolling(50).mean(), data[sel_stock].rolling(200).mean()
        
        c_tr1, c_tr2, c_tr3 = st.columns(3)
        with c_tr1:
            st.metric("Trend vs 200-MA", "‚úÖ BULLISH" if res['ltp'] > data['MA200'].iloc[-1] else "‚ùå BEARISH")
            st.write("**Interp:** Above 200-MA signals institutional support.")
        with c_tr2:
            st.metric("50/200 MA Cross", "üî• GOLDEN" if data['MA50'].iloc[-1] > data['MA200'].iloc[-1] else "‚ùÑÔ∏è DEATH")
            st.write("**Interp:** Golden signals momentum; Death signals structural decay.")
        with c_tr3:
            st.metric("Dist. 52W High", f"{((res['ltp'] / data[sel_stock].max())-1):.2%}")
            st.write("**Interp:** Relative strength indicator.")

        res_p, supp = data[sel_stock].tail(22).max(), data[sel_stock].tail(22).min()
        fig_sr = go.Figure()
        fig_sr.add_trace(go.Scatter(x=data.tail(252).index, y=data[sel_stock].tail(252), name="Price"))
        fig_sr.add_hline(y=res_p, line_dash="dash", line_color="green", annotation_text="Resis")
        fig_sr.add_hline(y=supp, line_dash="dash", line_color="red", annotation_text="Supp")
        st.plotly_chart(fig_sr, use_container_width=True)

    # --- TAB 3: STRATEGY ---
    with tab3:
        st.title("GARCH (1,1) Volatility & Strategy Forecast")
        ret_g = 100 * returns
        am = arch_model(ret_g, vol='Garch', p=1, q=1, dist='t')
        res_g = am.fit(disp="off")
        
        st.subheader("Volatility Status")
        m_vol1, m_vol2 = st.columns(2)
        m_vol1.metric("Shock Volatility", f"{res_g.conditional_volatility.iloc[-1]:.2f}")
        m_vol2.metric("Persistence (Beta)", f"{res_g.params['beta[1]']:.3f}")
        with st.expander("üîç Statistical Summary"): st.text(res_g.summary())

        fig_v = go.Figure()
        fig_v.add_trace(go.Scatter(x=res_g.conditional_volatility.index, y=res_g.conditional_volatility, name="Predicted Vol", line=dict(color='orange')))
        st.plotly_chart(fig_v, use_container_width=True)

        st.divider()
        strat_choice = st.selectbox("Methodology", ["Triple Golden Cross", "RSI", "SMA Crossover"])
        f_vol = np.sqrt(res_g.forecast(horizon=252).variance.values[-1, :]) / 100
        p_f = [res['ltp']]; np.random.seed(42)
        for i in range(252): p_f.append(p_f[-1] * np.exp(returns.mean() + f_vol[i] * np.random.standard_normal()))
        df_f = pd.DataFrame({'Close': p_f[1:]}, index=[data.index[-1] + timedelta(days=i) for i in range(1, 253)])
        
        if strat_choice == "Triple Golden Cross":
            t_col1, t_col2, t_col3 = st.columns(3)
            s_p = t_col1.number_input("Short MA", 10); m_p = t_col2.number_input("Mid MA", 50); l_p = t_col3.number_input("Long MA", 200)
            df_f['S'], df_f['M'], df_f['L'] = df_f['Close'].rolling(s_p).mean(), df_f['Close'].rolling(m_p).mean(), df_f['Close'].rolling(l_p).mean()
            df_f['Signal'] = np.where((df_f['S'] > df_f['M']) & (df_f['S'] < df_f['L']), 1, 0)
        elif strat_choice == "RSI":
            r_p = st.slider("RSI Period", 7, 30, 14)
            delta = df_f['Close'].diff(); g = delta.where(delta > 0, 0).rolling(r_p).mean(); l = -delta.where(delta < 0, 0).rolling(r_p).mean()
            df_f['Signal'] = np.where((100 - (100 / (1 + (g/l)))) < 30, 1, 0)
        else:
            df_f['Signal'] = np.where(df_f['Close'].rolling(20).mean() > df_f['Close'].rolling(50).mean(), 1, 0)

        s_ret_fore = df_f['Signal'].shift(1) * df_f['Close'].pct_change()
        st.subheader("Forecasted Performance Table (1-Year)")
        st.table(pd.DataFrame({
            "Metric": ["Annualized Return", "Annualized Risk", "Sharpe Value", "No. of Trades"],
            "Forecast": [f"{s_ret_fore.mean()*252:.2%}", f"{s_ret_fore.std()*np.sqrt(252):.2%}", f"{(s_ret_fore.mean()*252)/(s_ret_fore.std()*np.sqrt(252)) if s_ret_fore.std()!=0 else 0:.2f}", int(df_f['Signal'].diff().abs().sum())]
        }))
        
        fig_f = go.Figure()
        fig_f.add_trace(go.Scatter(x=df_f.index, y=df_f['Close'], name="Forecast Price"))
        buys = df_f[df_f['Signal'].diff() == 1]; sells = df_f[df_f['Signal'].diff() == -1]
        fig_f.add_trace(go.Scatter(x=buys.index, y=buys['Close'], mode='markers', name="Buy", marker=dict(symbol='triangle-up', size=15, color='green')))
        fig_f.add_trace(go.Scatter(x=sells.index, y=sells['Close'], mode='markers', name="Sell", marker=dict(symbol='triangle-down', size=15, color='red')))
        st.plotly_chart(fig_f, use_container_width=True)

    # --- TAB 4: CREDIT RISK ---
    with tab4:
        st.title("Credit Risk: Merton/KMV Structural Default Model")
        st.table(pd.DataFrame({"Component": ["ST Debt", "LT Debt", "Total Debt", "Market Cap"], 
                               "Value (Cr ‚Çπ)": [f"{res['st_d']:,.2f}", f"{res['lt_d']:,.2f}", f"{res['total_d']:,.2f}", f"{res['mcap']:,.2f}"]}))
        
        m_frame = st.radio("Framework", ["Merton Model", "KMV Model"])
        barr = (res['st_d'] + 0.5 * res['lt_d']) if m_frame == "KMV Model" else res['total_d']
        barr = st.number_input("Final Default Barrier (Barrier Value)", value=float(barr) if barr > 0 else 5000.0)
        
        def solve_m(E, se, L, r, T):
            def eq(p):
                V, sv = p; d1 = (np.log(V/L) + (r + 0.5 * sv**2) * T) / (sv * np.sqrt(T)); d2 = d1 - sv * np.sqrt(T)
                return [V * norm.cdf(d1) - L * np.exp(-r * T) * norm.cdf(d2) - E, (norm.cdf(d1) * V / E) * sv - se]
            return fsolve(eq, [E + L, se * (E / (E + L))])

        try:
            va, sa = solve_m(res['mcap'], ann_vol, barr, rf_rate, 1.0)
            dd_val = (np.log(va/barr) + (rf_rate - 0.5 * sa**2)) / sa; pd_val = norm.cdf(-dd_val)
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("Distance to Default (DD)", f"{dd_val:.2f} œÉ")
            c2.metric("Prob. of Default (PD)", f"{pd_val:.4%}")
            c3.metric("Asset Value (V)", f"‚Çπ{va:,.0f} Cr")
            c4.metric("Asset Volatility (œÉV)", f"{sa:.2%}")
            st.divider()
            st.write(f"**Interpretation:** Firm is **{dd_val:.2f} œÉ** from bankruptcy. Implied Asset Value is ‚Çπ{va:,.0f} Cr.")
        except: st.error("Solver failure.")

else: st.error("Rate Limit or Data Error. Please wait a few minutes and try again.")


